{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device.\n"
     ]
    }
   ],
   "source": [
    "# Setup the device to be used for training and evaluation\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    x = torch.ones(1, device=DEVICE)\n",
    "    print(\"Using CUDA device.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=DEVICE)\n",
    "    print(\"Using Apple Metal Performance Shaders (MPS) device.\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"No GPU found. Defaulting to CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import JupyterArgParser\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= global settings =========\n",
    "# Taken from i2sb paper with minor changes\n",
    "\n",
    "RESULT_DIR = Path(\"results\")\n",
    "\n",
    "# --------------- basic ---------------\n",
    "parser = JupyterArgParser()\n",
    "parser.add_argument(\"--seed\",           type=int,   default=0)\n",
    "parser.add_argument(\"--name\",           type=str,   default=None,        help=\"experiment ID\")\n",
    "parser.add_argument(\"--ckpt\",           type=str,   default=None,        help=\"resumed checkpoint name\")\n",
    "parser.add_argument(\"--device\",         type=str,   default=DEVICE,      help=\"type of device to use for training\")\n",
    "parser.add_argument(\"--gpu\",            type=int,   default=None,        help=\"set only if you wish to run on a particular GPU\")\n",
    "\n",
    "# --------------- model ---------------\n",
    "parser.add_argument(\"--image-size\",     type=int,   default=256)\n",
    "parser.add_argument(\"--t0\",             type=float, default=1e-4,        help=\"sigma start time in network parametrization\")\n",
    "parser.add_argument(\"--T\",              type=float, default=1.,          help=\"sigma end time in network parametrization\")\n",
    "parser.add_argument(\"--interval\",       type=int,   default=1000,        help=\"number of interval\")\n",
    "parser.add_argument(\"--beta-max\",       type=float, default=0.3,         help=\"max diffusion for the diffusion model\")\n",
    "parser.add_argument(\"--beta-schedule\",  type=str,   default=\"i2sb\",    help=\"schedule for beta\")\n",
    "parser.add_argument(\"--ot-ode\",         action=\"store_true\",             help=\"use OT-ODE model\")\n",
    "parser.add_argument(\"--clip-denoise\",   action=\"store_true\",             help=\"clamp predicted image to [-1,1] at each\")\n",
    "parser.add_argument(\"--use-fp16\",       action=\"store_true\",             help=\"use fp16 for training\")\n",
    "parser.add_argument(\"diffusion-type\",   type=str,   default=\"schrodinger_bridge\",      help=\"type of diffusion model\")\n",
    "\n",
    "# --------------- optimizer and loss ---------------\n",
    "parser.add_argument(\"--batch-size\",     type=int,   default=256)\n",
    "parser.add_argument(\"--microbatch\",     type=int,   default=2,           help=\"accumulate gradient over microbatch until full batch-size\")\n",
    "parser.add_argument(\"--num-itr\",        type=int,   default=1000000,     help=\"training iteration\")\n",
    "parser.add_argument(\"--lr\",             type=float, default=5e-5,        help=\"learning rate\")\n",
    "parser.add_argument(\"--lr-gamma\",       type=float, default=0.99,        help=\"learning rate decay ratio\")\n",
    "parser.add_argument(\"--lr-step\",        type=int,   default=1000,        help=\"learning rate decay step size\")\n",
    "parser.add_argument(\"--l2-norm\",        type=float, default=0.0)\n",
    "parser.add_argument(\"--ema\",            type=float, default=0.99)\n",
    "\n",
    "# --------------- path and logging ---------------\n",
    "parser.add_argument(\"--dataset-dir\",    type=Path,  default=\"/dataset\",  help=\"path to LMDB dataset\")\n",
    "parser.add_argument(\"--log-dir\",        type=Path,  default=\".log\",      help=\"path to log std outputs and writer data\")\n",
    "parser.add_argument(\"--log-writer\",     type=str,   default=None,        help=\"log writer: can be tensorbard, wandb, or None\")\n",
    "parser.add_argument(\"--wandb-api-key\",  type=str,   default=None,        help=\"unique API key of your W&B account; see https://wandb.ai/authorize\")\n",
    "parser.add_argument(\"--wandb-user\",     type=str,   default=None,        help=\"user name of your W&B account\")\n",
    "parser.add_argument(\"--ckpt-path\",      type=Path,  default=None,        help=\"path to save checkpoints\")\n",
    "parser.add_argument(\"--load\",           type=Path,  default=None,        help=\"path to load checkpoints\")\n",
    "parser.add_argument(\"--unet_path\",      type=str,   default=None,        help=\"path of UNet model to load for training\")\n",
    "\n",
    "# --------------- distributed ---------------\n",
    "parser.add_argument(\"--local-rank\",     type=int,   default=0)\n",
    "parser.add_argument(\"--global-rank\",    type=int,   default=0)\n",
    "parser.add_argument(\"--global-size\",    type=int,   default=1)\n",
    "\n",
    "opt = parser.get_options()\n",
    "# ========= path handle =========\n",
    "opt.name = \"test\"\n",
    "os.makedirs(opt.log_dir, exist_ok=True)\n",
    "opt.ckpt_path = RESULT_DIR / opt.name if opt.name else RESULT_DIR / \"temp\"\n",
    "os.makedirs(opt.ckpt_path, exist_ok=True)\n",
    "\n",
    "if opt.ckpt:\n",
    "    ckpt_file = RESULT_DIR / opt.ckpt / \"latest.pt\"\n",
    "    assert ckpt_file.exists()\n",
    "    opt.load = ckpt_file\n",
    "else:\n",
    "    opt.load = None\n",
    "\n",
    "# ========= auto assert =========\n",
    "assert opt.batch_size % opt.microbatch == 0, f\"{opt.batch_size=} is not dividable by {opt.microbatch}!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import SuperResolutionDataset\n",
    "\n",
    "# build dataset      \n",
    "hr_images = [torch.randn(3, opt.image_size, opt.image_size)] * 8\n",
    "lr_images = [torch.randn(3, opt.image_size, opt.image_size)] * 8\n",
    "assert len(hr_images) == len(lr_images)\n",
    "\n",
    "images = len(hr_images)\n",
    "split = int(0.8*images)\n",
    "train_hr, val_hr = hr_images[:split], hr_images[split:]\n",
    "train_lr, val_lr = lr_images[:split], lr_images[split:]\n",
    "\n",
    "train = SuperResolutionDataset(hr_images=train_hr, lr_images=train_lr, transform=None)\n",
    "val = SuperResolutionDataset(hr_images=val_hr, lr_images=val_lr, transform=None)\n",
    "\n",
    "# del train_hr, val_hr, train_lr, val_lr, hr_images, lr_images\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edmun\\anaconda3\\envs\\Mangrove\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\edmun\\anaconda3\\envs\\Mangrove\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built schrodinger_bridge Diffusion Model with 1000 steps and i2sb beta schedule!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n_inner_loop:  92%|█████████▏| 118/128 [04:11<00:21,  2.13s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m run = Runner(opt)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edmun\\Desktop\\VSCode Projects\\ml-mangrove\\Super Resolution\\Schrodinger Diffusion\\i2sb\\runner.py:153\u001b[39m, in \u001b[36mRunner.train\u001b[39m\u001b[34m(self, opt, train_dataset, val_dataset)\u001b[39m\n\u001b[32m    150\u001b[39m optimizer.zero_grad()\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_inner_loop), desc=\u001b[33m\"\u001b[39m\u001b[33mn_inner_loop\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# sample from boundary pair\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     x0, x1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     step = torch.randint(\u001b[32m0\u001b[39m, opt.interval, (x0.shape[\u001b[32m0\u001b[39m],)).to(opt.device) \n\u001b[32m    155\u001b[39m     xt = \u001b[38;5;28mself\u001b[39m.diffusion.q_sample(step, x0, x1, ot_ode=opt.ot_ode).to(opt.device) \u001b[38;5;66;03m# intermediate noisy image\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\edmun\\Desktop\\VSCode Projects\\ml-mangrove\\Super Resolution\\Schrodinger Diffusion\\i2sb\\runner.py:276\u001b[39m, in \u001b[36mRunner.sample_batch\u001b[39m\u001b[34m(self, opt, loader, scale_factor)\u001b[39m\n\u001b[32m    274\u001b[39m low_res_img, high_res_img = \u001b[38;5;28mnext\u001b[39m(loader)\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     high_res_img = \u001b[43mhigh_res_img\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     high_res_size = high_res_img.shape[-\u001b[32m2\u001b[39m:]\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# upscale the low res image to match the high res image\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from i2sb.runner import Runner\n",
    "\n",
    "# build runner\n",
    "run = Runner(opt)\n",
    "# train\n",
    "run.train(opt, train, val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transition plotter\n",
    "# source: https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "def plot_images(imgs, with_orig=False, row_title=None, **imshow_kwargs):\n",
    "    if not isinstance(imgs[0], list):\n",
    "        # Make a 2d grid even if there's just 1 row\n",
    "        imgs = [imgs]\n",
    "\n",
    "    num_rows = len(imgs)\n",
    "    num_cols = len(imgs[0]) + with_orig\n",
    "    _, axs = plt.subplots(figsize=(200,200), nrows=num_rows, ncols=num_cols, squeeze=False)\n",
    "    for row_idx, row in enumerate(imgs):\n",
    "        for col_idx, img in enumerate(row):\n",
    "            ax = axs[row_idx, col_idx]\n",
    "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
    "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "\n",
    "    if with_orig:\n",
    "        axs[0, 0].set(title='Original image')\n",
    "        axs[0, 0].title.set_size(8)\n",
    "    if row_title is not None:\n",
    "        for row_idx in range(num_rows):\n",
    "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mangrove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
