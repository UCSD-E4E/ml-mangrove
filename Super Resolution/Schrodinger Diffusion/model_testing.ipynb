{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c00efb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanwu/ml-mangrove/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from data import MemmapDataset\n",
    "from models import *\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchgeo.models import resnet18, resnet50, get_weight\n",
    "from typing import List\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "from data import SuperResolutionDataset\n",
    "import torch.nn.functional as F\n",
    "from i2sb.runner import Runner\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84480133",
   "metadata": {},
   "source": [
    "We test our final ResNet UNet Diffusion model after having:\n",
    "1. Trained our diffusion layer on NAIP data\n",
    "2. Tuned our decoder layer on 1m/pixel drone data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfba08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaccardLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    A Loss function to calculate the Jaccard index between the prediction and the target.\n",
    "\n",
    "    The Jaccard index is a measure of the similarity between two sets defined by the IOU (Intersection over Union).\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1e-10):\n",
    "        super(JaccardLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred : torch.tensor, y_true: torch.tensor):\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        \n",
    "        # Flatten the tensors to simplify the calculation\n",
    "        y_pred = y_pred.view(-1)\n",
    "        y_true = y_true.view(-1)\n",
    "        \n",
    "        # Calculate intersection and union\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        union = y_pred.sum() + y_true.sum() - intersection\n",
    "        \n",
    "        # Calculate the Jaccard index\n",
    "        jaccard_index = (intersection + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        # Return the Jaccard loss (1 - Jaccard index)\n",
    "        return 1 - jaccard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba5025e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Metal Performance Shaders (MPS) device.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOSS = JaccardLoss()\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"Using Apple Metal Performance Shaders (MPS) device.\\n\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"WARNING: No GPU found. Defaulting to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5a0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, dataloader: DataLoader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_TP = 0\n",
    "    total_FP = 0\n",
    "    total_FN = 0\n",
    "    total_TN = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            pred = model(x)\n",
    "            if isinstance(pred, tuple):\n",
    "                pred = pred[0]\n",
    "            loss = LOSS(pred, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = torch.sigmoid(pred).view(-1)\n",
    "            y = y.view(-1)\n",
    "            \n",
    "            TP = (pred * y).sum().item()\n",
    "            FP = ((1 - y) * pred).sum().item()\n",
    "            FN = (y * (1 - pred)).sum().item()\n",
    "            TN = ((1 - y) * (1 - pred)).sum().item()\n",
    "\n",
    "            total_TP += TP\n",
    "            total_FP += FP\n",
    "            total_FN += FN\n",
    "            total_TN += TN\n",
    "            \n",
    "            del x, y, pred, loss\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    precision = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    recall = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    iou = total_TP / (total_TP + total_FP + total_FN) if (total_TP + total_FP + total_FN) > 0 else 0\n",
    "    accuracy = (total_TP + total_TN) / (total_TP + total_FP + total_FN + total_TN) if (total_TP + total_FP + total_FN + total_TN) > 0 else 0\n",
    "    specificity = total_TN / (total_TN + total_FP) if (total_TN + total_FP) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        'Loss': avg_loss,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'IOU': iou,\n",
    "        'Accuracy': accuracy,\n",
    "        'Specificity': specificity\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212f7966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runner_ckpt.keys()=dict_keys(['net', 'ema', 'optimizer', 'sched'])\n",
      "tuned_decoder_ckpt.keys()=odict_keys(['layer1.0.weight', 'layer1.1.weight', 'layer1.1.bias', 'layer1.1.running_mean', 'layer1.1.running_var', 'layer1.1.num_batches_tracked', 'layer1.4.0.conv1.weight', 'layer1.4.0.bn1.weight', 'layer1.4.0.bn1.bias', 'layer1.4.0.bn1.running_mean', 'layer1.4.0.bn1.running_var', 'layer1.4.0.bn1.num_batches_tracked', 'layer1.4.0.conv2.weight', 'layer1.4.0.bn2.weight', 'layer1.4.0.bn2.bias', 'layer1.4.0.bn2.running_mean', 'layer1.4.0.bn2.running_var', 'layer1.4.0.bn2.num_batches_tracked', 'layer1.4.1.conv1.weight', 'layer1.4.1.bn1.weight', 'layer1.4.1.bn1.bias', 'layer1.4.1.bn1.running_mean', 'layer1.4.1.bn1.running_var', 'layer1.4.1.bn1.num_batches_tracked', 'layer1.4.1.conv2.weight', 'layer1.4.1.bn2.weight', 'layer1.4.1.bn2.bias', 'layer1.4.1.bn2.running_mean', 'layer1.4.1.bn2.running_var', 'layer1.4.1.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'center.decoder.0.weight', 'center.decoder.0.bias', 'center.decoder.1.weight', 'center.decoder.1.bias', 'center.decoder.1.running_mean', 'center.decoder.1.running_var', 'center.decoder.1.num_batches_tracked', 'center.decoder.4.weight', 'center.decoder.4.bias', 'center.decoder.5.weight', 'center.decoder.5.bias', 'center.decoder.5.running_mean', 'center.decoder.5.running_var', 'center.decoder.5.num_batches_tracked', 'center.decoder.7.weight', 'center.decoder.7.bias', 'skip_conv1.weight', 'skip_conv1.bias', 'skip_conv2.weight', 'skip_conv2.bias', 'skip_conv3.weight', 'skip_conv3.bias', 'decoder1.decoder.0.weight', 'decoder1.decoder.0.bias', 'decoder1.decoder.1.weight', 'decoder1.decoder.1.bias', 'decoder1.decoder.1.running_mean', 'decoder1.decoder.1.running_var', 'decoder1.decoder.1.num_batches_tracked', 'decoder1.decoder.4.weight', 'decoder1.decoder.4.bias', 'decoder1.decoder.5.weight', 'decoder1.decoder.5.bias', 'decoder1.decoder.5.running_mean', 'decoder1.decoder.5.running_var', 'decoder1.decoder.5.num_batches_tracked', 'decoder1.decoder.7.weight', 'decoder1.decoder.7.bias', 'decoder2.decoder.0.weight', 'decoder2.decoder.0.bias', 'decoder2.decoder.1.weight', 'decoder2.decoder.1.bias', 'decoder2.decoder.1.running_mean', 'decoder2.decoder.1.running_var', 'decoder2.decoder.1.num_batches_tracked', 'decoder2.decoder.4.weight', 'decoder2.decoder.4.bias', 'decoder2.decoder.5.weight', 'decoder2.decoder.5.bias', 'decoder2.decoder.5.running_mean', 'decoder2.decoder.5.running_var', 'decoder2.decoder.5.num_batches_tracked', 'decoder2.decoder.7.weight', 'decoder2.decoder.7.bias', 'classification_head.0.upsampler.0.weight', 'classification_head.0.upsampler.0.bias', 'classification_head.0.upsampler.1.weight', 'classification_head.0.upsampler.1.bias', 'classification_head.0.upsampler.1.running_mean', 'classification_head.0.upsampler.1.running_var', 'classification_head.0.upsampler.1.num_batches_tracked', 'classification_head.0.upsampler.3.weight', 'classification_head.0.upsampler.3.bias', 'classification_head.0.upsampler.4.weight', 'classification_head.0.upsampler.4.bias', 'classification_head.0.upsampler.4.running_mean', 'classification_head.0.upsampler.4.running_var', 'classification_head.0.upsampler.4.num_batches_tracked', 'classification_head.0.upsampler.6.weight', 'classification_head.0.upsampler.6.bias', 'classification_head.1.weight', 'classification_head.1.bias', 'classification_head.3.weight', 'classification_head.3.bias'])\n"
     ]
    }
   ],
   "source": [
    "# saved weights from runner (we want the diffusion layer weights specifically)\n",
    "# contains [net, ema, optimizer, sched] weights\n",
    "runner_ckpt_path = '/Users/evanwu/ml-mangrove/Super Resolution/Schrodinger Diffusion/results/test/model_001000.pt'\n",
    "runner_ckpt = torch.load(runner_ckpt_path, map_location=DEVICE)\n",
    "print(f\"runner_ckpt.keys()={runner_ckpt.keys()}\")\n",
    "\n",
    "# saved weights from decoder tuning\n",
    "tuned_decoder_ckpt_path = '/Users/evanwu/ml-mangrove/Super Resolution/Schrodinger Diffusion/decode_tune/ResNet_UNet_epoch_000030.pth'\n",
    "tuned_decoder_ckpt = torch.load(tuned_decoder_ckpt_path, map_location=DEVICE)\n",
    "print(f\"tuned_decoder_ckpt.keys()={tuned_decoder_ckpt.keys()}\")\n",
    "\n",
    "# original ALL_MOCO satellite weights\n",
    "# sat_ResNet_UNet = ResNet_UNet(resnet18(weights=get_weight(\"ResNet18_Weights.SENTINEL2_ALL_MOCO\")), num_input_channels=13)\n",
    "# sat_encoder_ckpt = sat_ResNet_UNet.state_dict()\n",
    "# print(f\"sat_encoder_ckpt.keys()={sat_encoder_ckpt.keys()}\")\n",
    "\n",
    "# original MOCO weights\n",
    "# orig_ckpt_path = '/Users/evanwu/ml-mangrove/DroneClassification/moco_resnet18_unet.pth'\n",
    "# orig_ckpt = torch.load('/Users/evanwu/ml-mangrove/DroneClassification/moco_resnet18_unet.pth', map_location=DEVICE)\n",
    "# print(f\"orig_ckpt.keys()={orig_ckpt.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d316e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'net' and 'ema' from checkpoint path\n",
      "Built schrodinger_bridge Diffusion Model with 1000 steps and i2sb beta schedule!\n",
      "Load Decoder Layers\n",
      "Skip loading of layer1.0.weight\n",
      "Skip loading of layer1.1.weight\n",
      "Skip loading of layer1.1.bias\n",
      "Skip loading of layer1.1.running_mean\n",
      "Skip loading of layer1.1.running_var\n",
      "Skip loading of layer1.1.num_batches_tracked\n",
      "Skip loading of layer1.4.0.conv1.weight\n",
      "Skip loading of layer1.4.0.bn1.weight\n",
      "Skip loading of layer1.4.0.bn1.bias\n",
      "Skip loading of layer1.4.0.bn1.running_mean\n",
      "Skip loading of layer1.4.0.bn1.running_var\n",
      "Skip loading of layer1.4.0.bn1.num_batches_tracked\n",
      "Skip loading of layer1.4.0.conv2.weight\n",
      "Skip loading of layer1.4.0.bn2.weight\n",
      "Skip loading of layer1.4.0.bn2.bias\n",
      "Skip loading of layer1.4.0.bn2.running_mean\n",
      "Skip loading of layer1.4.0.bn2.running_var\n",
      "Skip loading of layer1.4.0.bn2.num_batches_tracked\n",
      "Skip loading of layer1.4.1.conv1.weight\n",
      "Skip loading of layer1.4.1.bn1.weight\n",
      "Skip loading of layer1.4.1.bn1.bias\n",
      "Skip loading of layer1.4.1.bn1.running_mean\n",
      "Skip loading of layer1.4.1.bn1.running_var\n",
      "Skip loading of layer1.4.1.bn1.num_batches_tracked\n",
      "Skip loading of layer1.4.1.conv2.weight\n",
      "Skip loading of layer1.4.1.bn2.weight\n",
      "Skip loading of layer1.4.1.bn2.bias\n",
      "Skip loading of layer1.4.1.bn2.running_mean\n",
      "Skip loading of layer1.4.1.bn2.running_var\n",
      "Skip loading of layer1.4.1.bn2.num_batches_tracked\n",
      "Skip loading of layer2.0.conv1.weight\n",
      "Skip loading of layer2.0.bn1.weight\n",
      "Skip loading of layer2.0.bn1.bias\n",
      "Skip loading of layer2.0.bn1.running_mean\n",
      "Skip loading of layer2.0.bn1.running_var\n",
      "Skip loading of layer2.0.bn1.num_batches_tracked\n",
      "Skip loading of layer2.0.conv2.weight\n",
      "Skip loading of layer2.0.bn2.weight\n",
      "Skip loading of layer2.0.bn2.bias\n",
      "Skip loading of layer2.0.bn2.running_mean\n",
      "Skip loading of layer2.0.bn2.running_var\n",
      "Skip loading of layer2.0.bn2.num_batches_tracked\n",
      "Skip loading of layer2.0.downsample.0.weight\n",
      "Skip loading of layer2.0.downsample.1.weight\n",
      "Skip loading of layer2.0.downsample.1.bias\n",
      "Skip loading of layer2.0.downsample.1.running_mean\n",
      "Skip loading of layer2.0.downsample.1.running_var\n",
      "Skip loading of layer2.0.downsample.1.num_batches_tracked\n",
      "Skip loading of layer2.1.conv1.weight\n",
      "Skip loading of layer2.1.bn1.weight\n",
      "Skip loading of layer2.1.bn1.bias\n",
      "Skip loading of layer2.1.bn1.running_mean\n",
      "Skip loading of layer2.1.bn1.running_var\n",
      "Skip loading of layer2.1.bn1.num_batches_tracked\n",
      "Skip loading of layer2.1.conv2.weight\n",
      "Skip loading of layer2.1.bn2.weight\n",
      "Skip loading of layer2.1.bn2.bias\n",
      "Skip loading of layer2.1.bn2.running_mean\n",
      "Skip loading of layer2.1.bn2.running_var\n",
      "Skip loading of layer2.1.bn2.num_batches_tracked\n",
      "Skip loading of layer3.0.conv1.weight\n",
      "Skip loading of layer3.0.bn1.weight\n",
      "Skip loading of layer3.0.bn1.bias\n",
      "Skip loading of layer3.0.bn1.running_mean\n",
      "Skip loading of layer3.0.bn1.running_var\n",
      "Skip loading of layer3.0.bn1.num_batches_tracked\n",
      "Skip loading of layer3.0.conv2.weight\n",
      "Skip loading of layer3.0.bn2.weight\n",
      "Skip loading of layer3.0.bn2.bias\n",
      "Skip loading of layer3.0.bn2.running_mean\n",
      "Skip loading of layer3.0.bn2.running_var\n",
      "Skip loading of layer3.0.bn2.num_batches_tracked\n",
      "Skip loading of layer3.0.downsample.0.weight\n",
      "Skip loading of layer3.0.downsample.1.weight\n",
      "Skip loading of layer3.0.downsample.1.bias\n",
      "Skip loading of layer3.0.downsample.1.running_mean\n",
      "Skip loading of layer3.0.downsample.1.running_var\n",
      "Skip loading of layer3.0.downsample.1.num_batches_tracked\n",
      "Skip loading of layer3.1.conv1.weight\n",
      "Skip loading of layer3.1.bn1.weight\n",
      "Skip loading of layer3.1.bn1.bias\n",
      "Skip loading of layer3.1.bn1.running_mean\n",
      "Skip loading of layer3.1.bn1.running_var\n",
      "Skip loading of layer3.1.bn1.num_batches_tracked\n",
      "Skip loading of layer3.1.conv2.weight\n",
      "Skip loading of layer3.1.bn2.weight\n",
      "Skip loading of layer3.1.bn2.bias\n",
      "Skip loading of layer3.1.bn2.running_mean\n",
      "Skip loading of layer3.1.bn2.running_var\n",
      "Skip loading of layer3.1.bn2.num_batches_tracked\n",
      "Skip loading of layer4.0.conv1.weight\n",
      "Skip loading of layer4.0.bn1.weight\n",
      "Skip loading of layer4.0.bn1.bias\n",
      "Skip loading of layer4.0.bn1.running_mean\n",
      "Skip loading of layer4.0.bn1.running_var\n",
      "Skip loading of layer4.0.bn1.num_batches_tracked\n",
      "Skip loading of layer4.0.conv2.weight\n",
      "Skip loading of layer4.0.bn2.weight\n",
      "Skip loading of layer4.0.bn2.bias\n",
      "Skip loading of layer4.0.bn2.running_mean\n",
      "Skip loading of layer4.0.bn2.running_var\n",
      "Skip loading of layer4.0.bn2.num_batches_tracked\n",
      "Skip loading of layer4.0.downsample.0.weight\n",
      "Skip loading of layer4.0.downsample.1.weight\n",
      "Skip loading of layer4.0.downsample.1.bias\n",
      "Skip loading of layer4.0.downsample.1.running_mean\n",
      "Skip loading of layer4.0.downsample.1.running_var\n",
      "Skip loading of layer4.0.downsample.1.num_batches_tracked\n",
      "Skip loading of layer4.1.conv1.weight\n",
      "Skip loading of layer4.1.bn1.weight\n",
      "Skip loading of layer4.1.bn1.bias\n",
      "Skip loading of layer4.1.bn1.running_mean\n",
      "Skip loading of layer4.1.bn1.running_var\n",
      "Skip loading of layer4.1.bn1.num_batches_tracked\n",
      "Skip loading of layer4.1.conv2.weight\n",
      "Skip loading of layer4.1.bn2.weight\n",
      "Skip loading of layer4.1.bn2.bias\n",
      "Skip loading of layer4.1.bn2.running_mean\n",
      "Skip loading of layer4.1.bn2.running_var\n",
      "Skip loading of layer4.1.bn2.num_batches_tracked\n",
      "Load center.decoder.0.weight in to ResNet UNet Diffusion\n",
      "Load center.decoder.0.bias in to ResNet UNet Diffusion\n",
      "Load center.decoder.1.weight in to ResNet UNet Diffusion\n",
      "Load center.decoder.1.bias in to ResNet UNet Diffusion\n",
      "Load center.decoder.1.running_mean in to ResNet UNet Diffusion\n",
      "Load center.decoder.1.running_var in to ResNet UNet Diffusion\n",
      "Load center.decoder.1.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load center.decoder.4.weight in to ResNet UNet Diffusion\n",
      "Load center.decoder.4.bias in to ResNet UNet Diffusion\n",
      "Load center.decoder.5.weight in to ResNet UNet Diffusion\n",
      "Load center.decoder.5.bias in to ResNet UNet Diffusion\n",
      "Load center.decoder.5.running_mean in to ResNet UNet Diffusion\n",
      "Load center.decoder.5.running_var in to ResNet UNet Diffusion\n",
      "Load center.decoder.5.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load center.decoder.7.weight in to ResNet UNet Diffusion\n",
      "Load center.decoder.7.bias in to ResNet UNet Diffusion\n",
      "Load skip_conv1.weight in to ResNet UNet Diffusion\n",
      "Load skip_conv1.bias in to ResNet UNet Diffusion\n",
      "Load skip_conv2.weight in to ResNet UNet Diffusion\n",
      "Load skip_conv2.bias in to ResNet UNet Diffusion\n",
      "Load skip_conv3.weight in to ResNet UNet Diffusion\n",
      "Load skip_conv3.bias in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.0.weight in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.0.bias in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.1.weight in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.1.bias in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.1.running_mean in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.1.running_var in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.1.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.4.weight in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.4.bias in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.5.weight in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.5.bias in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.5.running_mean in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.5.running_var in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.5.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.7.weight in to ResNet UNet Diffusion\n",
      "Load decoder1.decoder.7.bias in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.0.weight in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.0.bias in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.1.weight in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.1.bias in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.1.running_mean in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.1.running_var in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.1.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.4.weight in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.4.bias in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.5.weight in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.5.bias in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.5.running_mean in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.5.running_var in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.5.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.7.weight in to ResNet UNet Diffusion\n",
      "Load decoder2.decoder.7.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.0.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.0.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.1.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.1.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.1.running_mean in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.1.running_var in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.1.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.3.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.3.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.4.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.4.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.4.running_mean in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.4.running_var in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.4.num_batches_tracked in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.6.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.0.upsampler.6.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.1.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.1.bias in to ResNet UNet Diffusion\n",
      "Load classification_head.3.weight in to ResNet UNet Diffusion\n",
      "Load classification_head.3.bias in to ResNet UNet Diffusion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import JupyterArgParser\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= global settings =========\n",
    "# Taken from i2sb paper with minor changes\n",
    "\n",
    "RESULT_DIR = Path(\"results\")\n",
    "\n",
    "# --------------- basic ---------------\n",
    "parser = JupyterArgParser()\n",
    "parser.add_argument(\"--seed\",           type=int,   default=0)\n",
    "parser.add_argument(\"--name\",           type=str,   default=None,        help=\"experiment ID\")\n",
    "parser.add_argument(\"--ckpt\",           type=str,   default=None,        help=\"resumed checkpoint name\")\n",
    "parser.add_argument(\"--device\",         type=str,   default=DEVICE,      help=\"type of device to use for training\")\n",
    "parser.add_argument(\"--gpu\",            type=int,   default=None,        help=\"set only if you wish to run on a particular GPU\")\n",
    "\n",
    "# --------------- model ---------------\n",
    "parser.add_argument(\"--image-size\",     type=int,   default=224)\n",
    "parser.add_argument(\"--t0\",             type=float, default=1e-4,        help=\"sigma start time in network parametrization\")\n",
    "parser.add_argument(\"--T\",              type=float, default=1.,          help=\"sigma end time in network parametrization\")\n",
    "parser.add_argument(\"--interval\",       type=int,   default=1000,        help=\"number of interval\")\n",
    "parser.add_argument(\"--beta-max\",       type=float, default=0.3,         help=\"max diffusion for the diffusion model\")\n",
    "parser.add_argument(\"--beta-schedule\",  type=str,   default=\"i2sb\",    help=\"schedule for beta\")\n",
    "parser.add_argument(\"--ot-ode\",         action=\"store_true\",             help=\"use OT-ODE model\")\n",
    "parser.add_argument(\"--clip-denoise\",   action=\"store_true\",             help=\"clamp predicted image to [-1,1] at each\")\n",
    "parser.add_argument(\"--use-fp16\",       action=\"store_true\",             help=\"use fp16 for training\")\n",
    "parser.add_argument(\"diffusion-type\",   type=str,   default=\"schrodinger_bridge\",      help=\"type of diffusion model\")\n",
    "\n",
    "# --------------- optimizer and loss ---------------\n",
    "parser.add_argument(\"--batch-size\",     type=int,   default=256)\n",
    "parser.add_argument(\"--microbatch\",     type=int,   default=4,           help=\"accumulate gradient over microbatch until full batch-size\")\n",
    "parser.add_argument(\"--num-itr\",        type=int,   default=10001,     help=\"training iteration\")\n",
    "parser.add_argument(\"--lr\",             type=float, default=5e-5,        help=\"learning rate\")\n",
    "parser.add_argument(\"--lr-gamma\",       type=float, default=0.99,        help=\"learning rate decay ratio\")\n",
    "parser.add_argument(\"--lr-step\",        type=int,   default=1000,        help=\"learning rate decay step size\")\n",
    "parser.add_argument(\"--l2-norm\",        type=float, default=0.0)\n",
    "parser.add_argument(\"--ema\",            type=float, default=0.99)\n",
    "\n",
    "# --------------- path and logging ---------------\n",
    "parser.add_argument(\"--dataset-dir\",    type=Path,  default=\"/dataset\",  help=\"path to LMDB dataset\")\n",
    "parser.add_argument(\"--log-dir\",        type=Path,  default=\".log\",      help=\"path to log std outputs and writer data\")\n",
    "parser.add_argument(\"--log-writer\",     type=str,   default=None,        help=\"log writer: can be tensorbard, wandb, or None\")\n",
    "parser.add_argument(\"--wandb-api-key\",  type=str,   default=None,        help=\"unique API key of your W&B account; see https://wandb.ai/authorize\")\n",
    "parser.add_argument(\"--wandb-user\",     type=str,   default=None,        help=\"user name of your W&B account\")\n",
    "parser.add_argument(\"--ckpt-path\",      type=Path,  default=None,        help=\"path to save checkpoints\")\n",
    "parser.add_argument(\"--load\",           type=Path,  default=runner_ckpt_path,        help=\"path to load checkpoints\")\n",
    "parser.add_argument(\"--unet_path\",      type=str,   default=None,        help=\"path of UNet model to load for training\")\n",
    "\n",
    "# --------------- distributed ---------------\n",
    "parser.add_argument(\"--local-rank\",     type=int,   default=0)\n",
    "parser.add_argument(\"--global-rank\",    type=int,   default=0)\n",
    "parser.add_argument(\"--global-size\",    type=int,   default=1)\n",
    "\n",
    "opt = parser.get_options()\n",
    "# ========= path handle =========\n",
    "opt.name = \"test\"\n",
    "os.makedirs(opt.log_dir, exist_ok=True)\n",
    "opt.ckpt_path = RESULT_DIR / opt.name if opt.name else RESULT_DIR / \"temp\"\n",
    "os.makedirs(opt.ckpt_path, exist_ok=True)\n",
    "\n",
    "# ========= auto assert =========\n",
    "assert opt.batch_size % opt.microbatch == 0, f\"{opt.batch_size=} is not dividable by {opt.microbatch}!\"\n",
    "\n",
    "\n",
    "run = Runner(opt)\n",
    "\n",
    "# run automatically has ResNet UNet Diffusion weights loaded from runner_ckpt_path\n",
    "# we want to override run.net decoder weights with tuned_decoder_ckpt_path\n",
    "base_dict = run.net.state_dict()\n",
    "# print(run.net)\n",
    "\n",
    "# encoder_prefixes = [\n",
    "#     'layer1',\n",
    "#     'layer2',\n",
    "#     'layer3',\n",
    "#     'layer4'\n",
    "# ]\n",
    "decoder_prefixes = [\n",
    "    'center.decoder',\n",
    "    'skip_conv',\n",
    "    'decoder1.decoder',\n",
    "    'decoder2.decoder',\n",
    "    'classification_head'\n",
    "]\n",
    "# print(f\"Load Encoder Layers\")\n",
    "# for k, v in sat_encoder_ckpt.items():\n",
    "#     if any(k.startswith(prefix) for prefix in encoder_prefixes):\n",
    "#         print(f\"Load {k} in to ResNet UNet Diffusion\")\n",
    "#         base_dict[k] = v\n",
    "#     else:\n",
    "#         print(f\"Skip loading of {k}\")\n",
    "print(f\"Load Decoder Layers\")\n",
    "for k, v in tuned_decoder_ckpt.items():\n",
    "    if any(k.startswith(prefix) for prefix in decoder_prefixes):\n",
    "        print(f\"Load {k} in to ResNet UNet Diffusion\")\n",
    "        base_dict[k] = v # might need to only load decoder weights, not encoder for this unet\n",
    "    else:\n",
    "        print(f\"Skip loading of {k}\")\n",
    "\n",
    "run.net.load_state_dict(base_dict) # load in updated dict to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e13d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, images, labels, mean=None, std=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "        if mean is not None and std is not None:\n",
    "            self.mean = torch.tensor(mean).view(13, 1, 1)\n",
    "            self.std = torch.tensor(std).view(13, 1, 1)\n",
    "        else:\n",
    "            self.mean = None\n",
    "            self.std = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = torch.tensor(self.images[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            img = (img - self.mean) / self.std\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d95c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jamaica_satellite shape: (584, 13, 224, 224) | jamaica_label shape: (584, 1, 224, 224)\n",
      "jamaica_loader of length 18\n"
     ]
    }
   ],
   "source": [
    "# load satellite images:labels\n",
    "jamaica_satellite = np.load('data/one_meter_drone/224dataset_satellite.npy', 'r')\n",
    "zero_channel = np.zeros((jamaica_satellite.shape[0], 1, jamaica_satellite.shape[2], jamaica_satellite.shape[3]))\n",
    "jamaica_satellite = np.concatenate((jamaica_satellite[:,:10], zero_channel, jamaica_satellite[:,10:]), axis=1)\n",
    "jamaica_label = np.load('data/one_meter_drone/224dataset_label.npy', 'r')\n",
    "assert len(jamaica_satellite) == len(jamaica_label), f\"jamaica_satellite b={jamaica_satellite.shape[0]} and jamaica_label b={jamaica_label.shape[0]} don't have the same B\"\n",
    "print(f\"jamaica_satellite shape: {jamaica_satellite.shape} | jamaica_label shape: {jamaica_label.shape}\")\n",
    "\n",
    "jamaica_dataset = SatelliteDataset(images=jamaica_satellite, labels=jamaica_label)\n",
    "jamaica_loader = DataLoader(jamaica_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "print(f\"jamaica_loader of length {len(jamaica_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59cd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18/18\r"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "total_TP = 0\n",
    "total_FP = 0\n",
    "total_FN = 0\n",
    "total_TN = 0\n",
    "\n",
    "run.net.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (sat, label) in enumerate(jamaica_loader):\n",
    "        print(f\"Batch {batch_idx + 1}/{len(jamaica_loader)}\", end=\"\\r\")\n",
    "        sat = sat.to(DEVICE)\n",
    "        label = label.float().to(DEVICE)\n",
    "\n",
    "        # encode\n",
    "        if len(sat.shape) == 3:\n",
    "            sat = sat.unsqueeze(0)\n",
    "        sat_l1 = run.net.layer1(sat)\n",
    "        sat_l2 = run.net.layer2(sat_l1)\n",
    "        sat_l3 = run.net.layer3(sat_l2)\n",
    "        sat_l4 = run.net.layer4(sat_l3)\n",
    "        sat_x1 = run.net.center(sat_l4)\n",
    "        \n",
    "        # diffuse\n",
    "        sat_xs, sat_pred_x0s = run.ddpm_sampling(opt, sat_x1, clip_denoise=opt.clip_denoise, verbose=False)\n",
    "        sat_x0_hat = sat_pred_x0s[:, -1].to(DEVICE)\n",
    "\n",
    "        # decode\n",
    "        # print(f\"sat_x0_hat.shape:{sat_x0_hat.shape} sat_l3.shape:{sat_l3.shape}\")\n",
    "        sat_d3 = torch.cat((sat_x0_hat, run.net.skip_conv1(sat_l3)), dim=1)\n",
    "        # print(f\"sat_d3.shape:{sat_d3.shape}\")\n",
    "        sat_d2 = run.net.decoder1(sat_d3)\n",
    "\n",
    "        # print(f\"sat_d2.shape:{sat_d2.shape} sat_l2.shape:{sat_l2.shape}\")\n",
    "        sat_d2 = torch.cat((sat_d2, run.net.skip_conv2(sat_l2)), dim=1)\n",
    "        # print(f\"sat_d2.shape:{sat_d2.shape}\")\n",
    "        sat_d1 = run.net.decoder2(sat_d2)\n",
    "\n",
    "        # print(f\"sat_d1.shape:{sat_d1.shape} sat_l1.shape:{sat_l1.shape}\")\n",
    "        sat_d1 = torch.cat((sat_d1, run.net.skip_conv3(sat_l1)), dim=1)\n",
    "        # print(f\"sat_d1.shape:{sat_d1.shape}\")\n",
    "        label_hat = run.net.classification_head(sat_d1)\n",
    "\n",
    "        # view if batch idx 0:\n",
    "        '''\n",
    "        if (batch_idx == 0):\n",
    "            item_idx = 5\n",
    "\n",
    "            # show satellite\n",
    "            fig, ax = plt.subplots(figsize=(3, 3))\n",
    "            chs = [3, 2, 1]\n",
    "            sat_rgb_arr = sat[item_idx, chs, :, :]\n",
    "            show(sat_rgb_arr.cpu().numpy().astype(np.uint8), ax=ax)\n",
    "\n",
    "            # show ground truth label\n",
    "            fig, ax = plt.subplots(figsize=(3, 3))\n",
    "            show(label[item_idx].cpu().numpy(), ax=ax)\n",
    "\n",
    "            # show pred label bin\n",
    "            fig, ax = plt.subplots(figsize=(3, 3))\n",
    "            label_hat_bin = (label_hat[item_idx].sigmoid() > 0.5).cpu().numpy()\n",
    "            show(label_hat_bin, ax=ax)\n",
    "            # print(f\"label_hat_bin: {label_hat_bin}\")\n",
    "\n",
    "            # show pred label probabiltiies\n",
    "            # plt.figure(figsize=(3, 3))\n",
    "            # label_hat_probs = label_hat[item_idx].sigmoid().cpu().numpy()\n",
    "            # plt.imshow(label_hat_probs.squeeze(), cmap='viridis', vmin=0, vmax=1)\n",
    "            # plt.show()\n",
    "            # print(f\"label_hat_probs: {label_hat_probs}\")\n",
    "\n",
    "\n",
    "            break\n",
    "        '''\n",
    "        \n",
    "        loss = LOSS(label_hat, label)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        label_hat = torch.sigmoid(label_hat).view(-1)\n",
    "        label = label.view(-1)\n",
    "\n",
    "        TP = (label_hat * label).sum().item()\n",
    "        FP = ((1 - label) * label_hat).sum().item()\n",
    "        FN = (label * (1 - label_hat)).sum().item()\n",
    "        TN = ((1 - label) * (1 - label_hat)).sum().item()\n",
    "\n",
    "        total_TP += TP\n",
    "        total_FP += FP\n",
    "        total_FN += FN\n",
    "        total_TN += TN\n",
    "\n",
    "avg_loss = total_loss / len(jamaica_loader)\n",
    "precision = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "recall = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "iou = total_TP / (total_TP + total_FP + total_FN) if (total_TP + total_FP + total_FN) > 0 else 0\n",
    "accuracy = (total_TP + total_TN) / (total_TP + total_FP + total_FN + total_TN) if (total_TP + total_FP + total_FN + total_TN) > 0 else 0\n",
    "specificity = total_TN / (total_TN + total_FP) if (total_TN + total_FP) > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aa0cf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Loss': 0.9450813002056546, 'Precision': 0.33021488587405157, 'Recall': 0.06262319525065735, 'f1_score': 0.10528058386579661, 'IOU': 0.05556526363180497, 'Accuracy': 0.5636455826723855, 'Specificity': 0.9117480943632463}\n"
     ]
    }
   ],
   "source": [
    "metrics = {\n",
    "        'Loss': avg_loss,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'IOU': iou,\n",
    "        'Accuracy': accuracy,\n",
    "        'Specificity': specificity\n",
    "    }\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e825fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741975.0888671875\n",
      "1504971.12890625\n",
      "11106271.96875\n",
      "15548157.84375\n"
     ]
    }
   ],
   "source": [
    "print(total_TP)\n",
    "print(total_FP)\n",
    "print(total_FN)\n",
    "print(total_TN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
