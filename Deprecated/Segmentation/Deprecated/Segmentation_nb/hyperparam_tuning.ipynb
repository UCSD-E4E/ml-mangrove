{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# hyperparamter tuning using keras tuner\n",
    "# https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import kerastuner as kt\n",
    "import segmentation_models as sm\n",
    "import numpy as np\n",
    "import os\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import random\n",
    "import imageio\n",
    "import time\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import hp, tpe, Trials, fmin, STATUS_OK\n",
    "from pydensecrf import utils\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global HEIGHT\n",
    "global WIDTH\n",
    "\n",
    "HEIGHT = 256\n",
    "WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TqdmUpTo(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(\"../dataset/testing/images/labels/mask_binary_28_47.tif\")\n",
    "# image = np.array(image)\n",
    "# np.unique(image)\n",
    "# image\n",
    "# #imageio.imread(\"../dataset/tuning/annotations/annotation_0.jpg\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pred_probs(img_dir, out_dir, weight_file):\n",
    "# generate prediction probabilites (.npy) for every image(.jpg) in the dataset\n",
    "# saved as numpy arrays(.npy)\n",
    "# expects all images in img_dir to be named \"image_0000.jpg\" (code is specific to image)\n",
    "# resulting prob files -> \"out_dir/pred-probs_0000.npy\"\n",
    "# will clear probabilites directory before writing\n",
    "\n",
    "    #Listing GPU info\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "       try:\n",
    "           for gpu in gpus:\n",
    "               tf.config.experimental.set_memory_growth(gpu, True)\n",
    "           logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "           print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "       except RuntimeError as e:\n",
    "           print(e)\n",
    "    \n",
    "    model = sm.Unet(\n",
    "        'vgg16', \n",
    "        #backbone,\n",
    "        input_shape=(HEIGHT, WIDTH, 3), \n",
    "        encoder_weights='imagenet', \n",
    "        weights=weight_file,\n",
    "        encoder_freeze=True,    # only training decoder network\n",
    "        classes= 2, \n",
    "        activation='softmax'\n",
    "    )\n",
    "\n",
    "    # Might be unnecessary\n",
    "    model.compile(\n",
    "        'Adam', \n",
    "        loss=sm.losses.DiceLoss(),\n",
    "        metrics=[sm.metrics.iou_score]\n",
    "    )\n",
    "    \n",
    "    if os.path.exists(out_dir):\n",
    "        os.system(\"rm \" + out_dir + \"/*\") # delete all files in /out_dir\n",
    "    else:\n",
    "        print(f\"out_dir:{out_dir} does not exist\")\n",
    "        \n",
    "        \n",
    "    if os.path.exists(img_dir):\n",
    "        full_dataset = glob(img_dir + \"*.jpg\") # glob all jpgs\n",
    "    else:\n",
    "        print(f\"img_dir:{img_dir} does not exist\")\n",
    "        os.exit()\n",
    "        \n",
    "    \n",
    "    for img_fp in tqdm(full_dataset):\n",
    "        img = np.asarray(Image.open(img_fp)) / 255.0 # assuming model uses normalized imgs\n",
    "        img = img[np.newaxis, ...] # needs (batch_size, h, w, channels)\n",
    "        pred_probs = model.predict(img)[0] # shape: -> (256, 256, 2)\n",
    "        pred_probs = 1 - pred_probs # classes do be flipped\n",
    "        pred_probs = pred_probs * 255\n",
    "        pred_probs = np.array(pred_probs).astype('uint8')  # should be binary (0, 255) values only\n",
    "        probs_fp = img_fp.replace(img_dir, out_dir)\n",
    "        probs_fp = probs_fp.replace(\"image\", \"pred-probs\")\n",
    "        probs_fp = probs_fp.replace(\".jpg\", \".npy\")\n",
    "        np.save(probs_fp, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(img_fp: str) -> dict:\n",
    "    \"\"\"Load an image, its annotation (true_mask), and predicted probabilites, returning\n",
    "    a dictionary. Assumes images are in \"tuning/images/\", annots are in \"tuning/annotations/\"\n",
    "    and pred probabilites are in \"tuning/probs/\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path : str\n",
    "        Image (not the mask) location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping an image, annotation, and predicted probabilites.\n",
    "    \"\"\"\n",
    "    img = np.asarray(Image.open(img_fp))\n",
    "    img = np.reshape(img, (256, 256, 3))\n",
    "\n",
    "    \n",
    "    tmask_fp = img_fp.replace(\"images\", \"annotations\")\n",
    "    tmask_fp = img_fp.replace(\"image\", \"annotation\")\n",
    "    true_mask = np.asarray(Image.open(tmask_fp))\n",
    "    true_mask = np.reshape(true_mask, (256, 256, 3))\n",
    "\n",
    "    probs_fp = img_fp.replace(\"images\", \"probs\")\n",
    "    probs_fp = probs_fp.replace(\"image\", \"pred-probs\")\n",
    "    probs_fp = probs_fp.replace(\".jpg\", \".npy\")\n",
    "    pred_probs = np.load(probs_fp) # these ones are already .npy\n",
    "    pred_probs = np.reshape(pred_probs, (256, 256, 2)) # probabilites of 2 classes, passed to densecrf\n",
    "\n",
    "    return {'image': img, 'true_mask': true_mask, 'pred_probs': pred_probs} # all Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_dataset(sample_percentage: float):\n",
    "# Assume all data is in ../dataset/tuning/\n",
    "# Load datasets AFTER calling unet_funcs_tuning.tune_setup()\n",
    "    \"\"\"\n",
    "    loads test images, ground truth masks, and predicted probabilites into dataset, \n",
    "    sample_percentage is a float < 1 that represents how much of the full dataset will be used\n",
    "    in tuning\n",
    "    \n",
    "    Returns: tuple\n",
    "    -------\n",
    "        \n",
    "        (test_dataset, DATASET_SIZE): (iter, int)\n",
    "        \n",
    "        # test_dataset: a \"map\" iter with dicts of three np.arrays\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    assert sample_percentage < 1\n",
    "    \n",
    "    SEED = 42\n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 1000\n",
    "    \n",
    "    tuning_data = \"../dataset/tuning/\"\n",
    "    \n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "            \n",
    "    full_dataset = glob(tuning_data + \"images/*.jpg\") # get tiles, full dataset ~106560 imgs\n",
    "    DATASET_SIZE = len(full_dataset)\n",
    "    print(f\"The Tuning FULL Dataset contains {DATASET_SIZE} images.\")\n",
    "\n",
    "    SAMPLE_SIZE = int(DATASET_SIZE * sample_percentage) # how many dataset entries to use in tuning\n",
    "    print(f\"Taking sample of {SAMPLE_SIZE} from main dataset..\")\n",
    "    test_dataset = random.sample(full_dataset, SAMPLE_SIZE)\n",
    "    print(\"Done\")\n",
    "    print(f\"Loading mask, model output probabilites, and images into memory..\")\n",
    "    test_dataset = map(parse_image, test_dataset)# Creating dict linking images, true_mask, and pred_probs\n",
    "    print(\"Done\")\n",
    "    #test_dataset = map(load_image_val, test_dataset)\n",
    "    \n",
    "    return test_dataset, SAMPLE_SIZE # a map iterator, int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_densecrf(crf_params: dict):\n",
    "    \"\"\"\n",
    "    returns a densecrf() function with parameters from dict: crf_params\n",
    "    called within objective function to allow crf to be modular\n",
    "    \n",
    "    pydensercrf: https://github.com/lucasb-eyer/pydensecrf\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    crf_params:\n",
    "        # Except for 'gauss_scale_dims', all values are used in 'densecrf()'\n",
    "        'gauss_compat': int # \"strength of energy\"\n",
    "        'bilat_compat': int\n",
    "        'bilat_scale_dims': (int, int) # horiz, vert standard deviation\n",
    "        'gauss_scale_dims': (int, int) # used in test loop\n",
    "        'bilat_scale_chans': (int, int, int) # RGB standard deviation\n",
    "    \"\"\"\n",
    "    g_compat = crf_params['gauss_compat'] # strength\n",
    "    bi_compat = crf_params['bilat_compat']\n",
    "    bi_sdims = (crf_params['bilat_scale_dims'], crf_params['bilat_scale_dims'])\n",
    "    bi_schans = (crf_params['bilat_scale_chans'], crf_params['bilat_scale_chans'], crf_params['bilat_scale_chans'])\n",
    "\n",
    "    def densecrf(pred_mask, img, g_feats):\n",
    "        img = np.reshape(img, (256, 256, 3))\n",
    "        softmax = pred_mask.transpose((2, 0, 1))\n",
    "        unary = utils.unary_from_softmax(softmax)\n",
    "    \n",
    "        # The inputs should be C-continious -- we are using Cython wrapper\n",
    "        unary = np.ascontiguousarray(unary)\n",
    "    \n",
    "        d = dcrf.DenseCRF(img.shape[0] * img.shape[1], 2) # h * w, channels\n",
    "        d.setUnaryEnergy(unary)\n",
    "    \n",
    "        #gaussian penalizes small pieces of segmentation that are spatially isolated\n",
    "        d.addPairwiseEnergy(g_feats, compat=g_compat,\n",
    "                    kernel=dcrf.DIAG_KERNEL,\n",
    "                    normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    \n",
    "        # This creates the color-dependent features --\n",
    "        # because the segmentation that we get from CNN are too coarse\n",
    "        # and we can use local color features to refine them\n",
    "        bi_feats = utils.create_pairwise_bilateral(sdims=bi_sdims,\n",
    "                        schan=bi_schans, img=img, chdim=2)\n",
    "\n",
    "        d.addPairwiseEnergy(bi_feats, compat=bi_compat,\n",
    "                     kernel=dcrf.DIAG_KERNEL,\n",
    "                     normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    \n",
    "        Q = d.inference(1) # could be tuned\n",
    "        res = np.argmax(Q, axis=0).reshape((img.shape[0], img.shape[1]))\n",
    "        return np.reshape(res, (256, 256, 1))\n",
    "    \n",
    "    return densecrf # returns function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(array, val_array):\n",
    "    assert array.shape == val_array.shape, \"Array and Validation Array have different sizes.\"\n",
    "    np.reshape(array, (HEIGHT, WIDTH))\n",
    "    np.reshape(val_array, (HEIGHT, WIDTH))\n",
    "    intersection = np.sum(array == val_array)\n",
    "    union = array.shape[0] * array.shape[1]\n",
    "    res = intersection / union\n",
    "    assert res <= 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(weights, crf_params: dict, test_dataset: iter , DATASET_SIZE: int):\n",
    "    \"\"\"\n",
    "    objective function takes in crf_params and runs \n",
    "    testing on dataset from compile_dataset()\n",
    "    \n",
    "    Paramaters\n",
    "    ----------\n",
    "    \n",
    "        crf_params: dict\n",
    "            # Except for 'gauss_scale_dims', all values are used in 'densecrf()'\n",
    "            'gauss_compat': int # \"strength of energy\"\n",
    "            'bilat_compat': int\n",
    "            'bilat_scale_dims': (int, int) # horiz, vert standard deviation\n",
    "            'gauss_scale_dims': (int, int) # only used in objective func      \n",
    "            'bilat_scale_chans': (int, int, int) # RGB standard deviation\n",
    "        \n",
    "        test_dataset: iter\n",
    "             # map from list[dicts]:\n",
    "            'image': np.array # (256, 256, 3) # image rgb data used by crf\n",
    "            'true_mask': np.array # (256, 256, 3) # later trimmed to one channel image              \n",
    "            'pred_probs': np.array # (256, 256, 2) # probs of two classes passed to crf\n",
    "                \n",
    "    Returns: mean_iou(float)\n",
    "    \"\"\"\n",
    "    \n",
    "    def probs_to_mask(pred_probs, densecrf, img, g_feats: int):\n",
    "        pred_mask = densecrf(pred_probs, img, g_feats) # whats getting tuned\n",
    "#         pred_mask = tf.argmax(pred_probs, axis=-1)\n",
    "#         pred_mask = pred_mask[..., tf.newaxis]\n",
    "        pred_mask = 1 - pred_mask\n",
    "        pred_mask = pred_mask * 255\n",
    "        return np.array(pred_mask).astype('uint8') # binary (0,255) values now\n",
    "        \n",
    "    \n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    #print(f\"Tensorflow ver. {tf.__version__}\")\n",
    "\n",
    "    # For reproducibility\n",
    "    SEED = 42\n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 1000\n",
    "    \n",
    "    densecrf = create_densecrf(crf_params) # crf function, for tuning!\n",
    "    g_sdims = crf_params['gauss_scale_dims'] # another part of crf\n",
    "    \n",
    "    #Listing GPU info\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "       try:\n",
    "           for gpu in gpus:\n",
    "               tf.config.experimental.set_memory_growth(gpu, True)\n",
    "           logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "           #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "       except RuntimeError as e:\n",
    "           print(e)\n",
    "            \n",
    "    model = sm.Unet(\n",
    "        'vgg16', \n",
    "        #backbone,\n",
    "        input_shape=(HEIGHT, WIDTH, 3), \n",
    "        encoder_weights='imagenet', \n",
    "        weights=weights,\n",
    "        encoder_freeze=True,    # only training decoder network\n",
    "        classes= 2, \n",
    "        activation='softmax'\n",
    "    )\n",
    "\n",
    "    # Might be unnecessary\n",
    "    model.compile(\n",
    "        'Adam', \n",
    "        #loss=sm.losses.bce_jaccard_loss, \n",
    "        loss=sm.losses.DiceLoss(),\n",
    "        metrics=[sm.metrics.iou_score]\n",
    "    )\n",
    "\n",
    "    # CRF Pairwise energies:\n",
    "    # This potential penalizes small pieces of segmentation that are\n",
    "    # spatially isolated -- enforces more spatially consistent segmentations\n",
    "    \n",
    "    g_sdims = crf_params['gauss_scale_dims'] # scaling factor\n",
    "    g_feats = utils.create_pairwise_gaussian(sdims=(g_sdims, g_sdims), shape=(HEIGHT, WIDTH))\n",
    "    \n",
    "    tot_iou = 0 # counter for mean_iou\n",
    "    crf_time = 0 \n",
    "\n",
    "    #print(f\"The Tuning Dataset contains {DATASET_SIZE} images.\")\n",
    "    for np_dict in test_dataset:\n",
    "        img = np_dict['image'] # (256, 256, 3) RGB \n",
    "        true_mask = np_dict['true_mask'][:, :, :1] # (256, 256, 3)->(256, 256, 1) grayscale        \n",
    "        pred_probs = np_dict['pred_probs'] # (256, 256, 2) output probs\n",
    "        \n",
    "        start = time.time()\n",
    "        # shape: (256, 256, 2) --densecrf-> (256, 256, 1)\n",
    "        pred_mask = probs_to_mask(pred_probs, densecrf, img, g_feats) \n",
    "        crf_time += time.time() - start\n",
    "        tot_iou += IOU(pred_mask, true_mask)\n",
    "    \n",
    "    mean_iou = tot_iou/DATASET_SIZE # objective value\n",
    "#     print(\"Avg crf time: \", crf_time/DATASET_SIZE ) # display avg time spent int densecrf func\n",
    "#     print(\"Mean IOU: \", mean_iou ) # display iou\n",
    "    \n",
    "    return -1 * mean_iou # optimization attempts to lower this number, so invert it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_wrapper(crf_params):\n",
    "    weights = \"../dataset/training/weights/08_10_vgg16_200_full_weight.h5\"\n",
    "    test_dataset = dataset\n",
    "    test_size = size \n",
    "    return objective(weights, crf_params, test_dataset, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_crf_params = {\n",
    "#     'gauss_compat': 3,\n",
    "#     'bilat_compat': 3,\n",
    "#     'gauss_scale_dims' : 3,  # only used in objective func      \n",
    "#     'bilat_scale_dims' : 3, \n",
    "#     'bilat_scale_chans': 3\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "The Tuning FULL Dataset contains 106560 images.\n",
      "Taking sample of 5328 from main dataset..\n",
      "Done\n",
      "Loading mask, model output probabilites, and images into memory..\n",
      "Done\n",
      "CPU times: user 12.3 s, sys: 634 ms, total: 13 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "global dataset\n",
    "global size\n",
    "dataset, size = compile_dataset(0.05)\n",
    "dataset = list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106560/106560 [43:23<00:00, 40.93it/s] \n"
     ]
    }
   ],
   "source": [
    "# generate prediction probabilites\n",
    "weight_file = \"../dataset/training/weights/08_10_vgg16_200_full_weight.h5\"\n",
    "img_dir = \"../dataset/tuning/images/\"\n",
    "out_dir = \"../dataset/tuning/probs/\"\n",
    "\n",
    "gen_pred_probs(img_dir, out_dir, weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': array([[[ 40, 102,  91],\n",
       "         [ 42, 104,  93],\n",
       "         [ 45, 107,  96],\n",
       "         ...,\n",
       "         [ 36, 107,  93],\n",
       "         [ 40, 111,  97],\n",
       "         [ 44, 115, 101]],\n",
       " \n",
       "        [[ 42, 104,  93],\n",
       "         [ 43, 105,  94],\n",
       "         [ 45, 107,  96],\n",
       "         ...,\n",
       "         [ 38, 109,  95],\n",
       "         [ 42, 113,  99],\n",
       "         [ 44, 115, 101]],\n",
       " \n",
       "        [[ 44, 106,  95],\n",
       "         [ 44, 106,  95],\n",
       "         [ 45, 107,  96],\n",
       "         ...,\n",
       "         [ 40, 111,  97],\n",
       "         [ 42, 113,  99],\n",
       "         [ 43, 114, 100]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 41, 104,  93],\n",
       "         [ 39, 102,  91],\n",
       "         [ 37, 100,  89],\n",
       "         ...,\n",
       "         [ 36, 107,  93],\n",
       "         [ 37, 108,  94],\n",
       "         [ 38, 109,  95]],\n",
       " \n",
       "        [[ 40, 103,  92],\n",
       "         [ 38, 101,  90],\n",
       "         [ 37, 100,  89],\n",
       "         ...,\n",
       "         [ 35, 106,  92],\n",
       "         [ 37, 108,  94],\n",
       "         [ 39, 110,  96]],\n",
       " \n",
       "        [[ 39, 102,  91],\n",
       "         [ 38, 101,  90],\n",
       "         [ 37, 100,  89],\n",
       "         ...,\n",
       "         [ 35, 106,  92],\n",
       "         [ 37, 108,  94],\n",
       "         [ 40, 111,  97]]], dtype=uint8),\n",
       " 'true_mask': array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " 'pred_probs': array([[[254,   0],\n",
       "         [254,   0],\n",
       "         [254,   0],\n",
       "         ...,\n",
       "         [182,  72],\n",
       "         [  0, 254],\n",
       "         [  0, 254]],\n",
       " \n",
       "        [[254,   0],\n",
       "         [255,   0],\n",
       "         [255,   0],\n",
       "         ...,\n",
       "         [255,   0],\n",
       "         [255,   0],\n",
       "         [252,   2]],\n",
       " \n",
       "        [[254,   0],\n",
       "         [255,   0],\n",
       "         [255,   0],\n",
       "         ...,\n",
       "         [255,   0],\n",
       "         [255,   0],\n",
       "         [254,   0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[253,   1],\n",
       "         [254,   0],\n",
       "         [255,   0],\n",
       "         ...,\n",
       "         [172,  82],\n",
       "         [221,  33],\n",
       "         [247,   7]],\n",
       " \n",
       "        [[182,  72],\n",
       "         [254,   0],\n",
       "         [254,   0],\n",
       "         ...,\n",
       "         [150, 104],\n",
       "         [184,  70],\n",
       "         [247,   7]],\n",
       " \n",
       "        [[ 33, 221],\n",
       "         [243,  11],\n",
       "         [254,   0],\n",
       "         ...,\n",
       "         [209,  45],\n",
       "         [237,  17],\n",
       "         [232,  22]]], dtype=uint8)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective(weight_file, test_crf_params, dataset, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the domain space\n",
    "test_space = {\n",
    "    'gauss_compat': scope.int(hp.randint('gauss_compat', 10)),\n",
    "    'bilat_compat': scope.int(hp.randint('bilat_compat', 10)),\n",
    "    'gauss_scale_dims' : scope.int(hp.quniform('gauss_scale_dims', 1, 10, q=1)),  # only used in objective func      \n",
    "    'bilat_scale_dims' : scope.int(hp.quniform('bilat_scale_dims', 1, 10, q=1)), \n",
    "    'bilat_scale_chans': scope.int(hp.quniform('bilat_scale_chans',1, 10, q=1)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the algorithm\n",
    "tpe_algo = tpe.suggest\n",
    "\n",
    "# Create a trials object\n",
    "tpe_trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [07:50<6:23:58, 470.18s/trial, best loss: -0.3004256526271144]"
     ]
    }
   ],
   "source": [
    "best = fmin(\n",
    "    objective_wrapper,\n",
    "    space=test_space,\n",
    "    algo=tpe_algo,\n",
    "    max_evals=50,\n",
    "    trials=tpe_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': -0.30891496641141875, 'status': 'ok'},\n",
       " {'loss': -0.30891417311476516, 'status': 'ok'},\n",
       " {'loss': -0.30891524420844185, 'status': 'ok'},\n",
       " {'loss': -0.3089151038779869, 'status': 'ok'},\n",
       " {'loss': -0.30891492058922937, 'status': 'ok'},\n",
       " {'loss': -0.30891493777255036, 'status': 'ok'},\n",
       " {'loss': -0.308915241344555, 'status': 'ok'},\n",
       " {'loss': -0.3089153129417259, 'status': 'ok'},\n",
       " {'loss': -0.30891492918088986, 'status': 'ok'},\n",
       " {'loss': -0.3089149062697952, 'status': 'ok'},\n",
       " {'loss': -0.3089152928945181, 'status': 'ok'},\n",
       " {'loss': -0.308914926317003, 'status': 'ok'},\n",
       " {'loss': -0.3089143535396358, 'status': 'ok'},\n",
       " {'loss': -0.30891521556957346, 'status': 'ok'},\n",
       " {'loss': -0.30891614060502154, 'status': 'ok'},\n",
       " {'loss': -0.30891494350032406, 'status': 'ok'},\n",
       " {'loss': -0.3089152470723287, 'status': 'ok'},\n",
       " {'loss': -0.3089140986537074, 'status': 'ok'},\n",
       " {'loss': -0.3089149177253425, 'status': 'ok'},\n",
       " {'loss': -0.30891485471983215, 'status': 'ok'},\n",
       " {'loss': -0.3089171229182063, 'status': 'ok'},\n",
       " {'loss': -0.308916673287973, 'status': 'ok'},\n",
       " {'loss': -0.30891662173801, 'status': 'ok'},\n",
       " {'loss': -0.3089171229182063, 'status': 'ok'},\n",
       " {'loss': -0.30891572247754345, 'status': 'ok'},\n",
       " {'loss': -0.3089171229182063, 'status': 'ok'},\n",
       " {'loss': -0.3089165615963864, 'status': 'ok'},\n",
       " {'loss': -0.3089153874027836, 'status': 'ok'},\n",
       " {'loss': -0.30891602318566125, 'status': 'ok'},\n",
       " {'loss': -0.3089153129417259, 'status': 'ok'},\n",
       " {'loss': -0.3089153014861786, 'status': 'ok'},\n",
       " {'loss': -0.3089165673241601, 'status': 'ok'},\n",
       " {'loss': -0.3089154017222178, 'status': 'ok'},\n",
       " {'loss': -0.3089157167497698, 'status': 'ok'},\n",
       " {'loss': -0.3089167019268414, 'status': 'ok'},\n",
       " {'loss': -0.30891631530211855, 'status': 'ok'},\n",
       " {'loss': -0.30891521556957346, 'status': 'ok'},\n",
       " {'loss': -0.30891555350822014, 'status': 'ok'},\n",
       " {'loss': -0.3089152642556497, 'status': 'ok'},\n",
       " {'loss': -0.30891500936972127, 'status': 'ok'},\n",
       " {'loss': -0.30891565660814624, 'status': 'ok'},\n",
       " {'loss': -0.3089147401643587, 'status': 'ok'},\n",
       " {'loss': -0.30891559646652267, 'status': 'ok'},\n",
       " {'loss': -0.3089155048221439, 'status': 'ok'},\n",
       " {'loss': -0.3089152098417998, 'status': 'ok'},\n",
       " {'loss': -0.30891527571119703, 'status': 'ok'},\n",
       " {'loss': -0.3089151296529684, 'status': 'ok'},\n",
       " {'loss': -0.30891521270568667, 'status': 'ok'},\n",
       " {'loss': -0.3089150952863264, 'status': 'ok'},\n",
       " {'loss': -0.30891665896853887, 'status': 'ok'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpe_trials.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tensorflow",
   "language": "python",
   "name": "conda-env-py37_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
