{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load \"../ml-mangrove/Segmentation/unet.py\"\n",
    "import segmentation_models as sm\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import rasterio\n",
    "import subprocess\n",
    "import tensorflow_datasets as tfds\n",
    "import shutil\n",
    "import pydensecrf.densecrf as dcrf\n",
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "from IPython.lib.display import Audio\n",
    "from pydensecrf import utils\n",
    "from gis_utils import raster\n",
    "from rasterio.plot import show\n",
    "from PIL import Image\n",
    "from segmentation_models.utils import set_trainable\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing notebooks\n",
    "#from ipynb.fs.full.<notebook_name> import *\n",
    "from ipynb.fs.full.create_seg_dataset import create_seg_dataset\n",
    "from ipynb.fs.full.gen_seg_labels import gen_seg_labels, tif_to_jpg, tile_raster\n",
    "from ipynb.fs.full.raster_mask import raster_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resources: https://yann-leguilly.gitlab.io/post/2019-12-14-tensorflow-tfdata-segmentation/\n",
    "\n",
    "'''\n",
    "Documentation/Usage: This script is meant to be called with command line arguments.\n",
    "--width (required): tile width\n",
    "--input_rasters (required): space separated list of rasters (orthomosaics)\n",
    "--input_vectors (required for training): space separated list of shapefiles (ordering should correspond with rasters)\n",
    "--train: Flag. Add if training.\n",
    "--test: Flag. Add if testing.\n",
    "--weights (required): path to weights file, either to write to for training, or to use for testing (.h5)\n",
    "--backbone (required): name of backbone to use, ex: resnet34, vgg16\n",
    "\n",
    "For training it should be sufficient to just call the script using the list of rasters and vectors (and other required arguments), \n",
    "and currently you have to manually set the hyperparams in the code, but this should eventually be offloaded to a settings file or \n",
    "command line arguments. This will result in the training weights being saved in the specified .h5 file.\n",
    "\n",
    "For testing you just need to call the script on the list of rasters and it will produce a mask of the entire\n",
    "orthomosaic.\n",
    "'''\n",
    "#keras.backend.set_image_data_format('channels_first')\n",
    "sm.set_framework('tf.keras')    # need this otherwise currently a bug in model.fit when used with tf.Datasets\n",
    "\n",
    "# Globals\n",
    "N_CHANNELS = 3\n",
    "WIDTH = 256\n",
    "HEIGHT = 256\n",
    "LOSS_FUNC = sm.losses.DiceLoss()\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(img_path: str) -> dict:\n",
    "    \"\"\"Load an image and its annotation (mask) and returning\n",
    "    a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path : str\n",
    "        Image (not the mask) location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping an image and its annotation.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # Creating mask path from image path\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"images\", \"annotations\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"image\", \"annotation\")\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "\n",
    "    # The masks contain a class index for each pixels\n",
    "    mask = tf.image.decode_jpeg(mask, channels=1)\n",
    "    mask = tf.image.convert_image_dtype(mask, tf.uint8)\n",
    "    \n",
    "    #mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
    "    # Note that we have to convert the new value (0)\n",
    "    # With the same dtype than the tensor itself\n",
    "    \n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "    \"\"\"Rescale the pixel values of the images/masks between 0.0 and 1.0\n",
    "    compared to [0,255] originally.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_image : tf.Tensor\n",
    "        Tensorflow tensor containing an image of size [SIZE,SIZE,3].\n",
    "    input_mask : tf.Tensor\n",
    "        Tensorflow tensor containing an annotation of size [SIZE,SIZE,1].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Normalized image and its annotation.\n",
    "    \"\"\"\n",
    "    input_mask = tf.cast(input_mask, tf.float32) / 255.0 # attempting to fix metrics\n",
    "    input_mask = tf.round(input_mask)\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "    \"\"\"Apply some transformations to an input dictionary\n",
    "    containing a train image and its annotation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    An annotation is a regular  channel image.\n",
    "    If a transformation such as rotation is applied to the image,\n",
    "    the same transformation has to be applied on the annotation also.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapoint : dict\n",
    "        A dict containing an image and its annotation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A modified image and its annotation.\n",
    "    \"\"\"\n",
    "   \n",
    "    input_image = tf.image.resize(datapoint['image'], (HEIGHT, WIDTH))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (HEIGHT, WIDTH))\n",
    "    #input_mask = tf.image.rgb_to_grayscale(datapoint['segmentation_mask'])\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "    \n",
    "    #input_mask = tf.reshape(input_mask, (HEIGHT, WIDTH))  # removing single channel\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    \n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_val(datapoint: dict) -> tuple:\n",
    "    \"\"\"Normalize and resize a test image and its annotation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Since this is for the val set, we don't need to apply\n",
    "    any data augmentation technique.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapoint : dict\n",
    "        A dict containing an image and its annotation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A modified image and its annotation.\n",
    "    \"\"\"\n",
    "    input_image = tf.image.resize(datapoint['image'], (HEIGHT, WIDTH))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (HEIGHT, WIDTH))\n",
    "    \n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "    #input_mask = tf.reshape(input_mask, (HEIGHT, WIDTH)) # removing single channel\n",
    "\n",
    "    \n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image(datapoint: dict) -> tuple:\n",
    "    \"\"\"Loads and image and resizes it\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapoint : dict\n",
    "        A dict containing an image and its annotation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        A image and its annotation.\n",
    "    \"\"\"\n",
    "    input_image = tf.image.resize(datapoint['image'], (HEIGHT, WIDTH))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (HEIGHT, WIDTH))\n",
    "    #input_mask = tf.image.resize(datapoint['label'], (HEIGHT, WIDTH))\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    #return pred_mask[0]\n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model=None, dataset=None, num=1):\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = model.predict(image)\n",
    "            display([image[0], mask[0], create_mask(pred_mask[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, callback, raster_file, vector_file):\n",
    "    #delete all files with extension\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    folderpath = \"../dataset/training/\"\n",
    "    for file_name in os.listdir(folderpath + \"images/images\"):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            os.remove(folderpath + \"images/images/\" + file_name)\n",
    "    for file_name in os.listdir(folderpath + \"images\"):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            os.remove(folderpath + \"images/\" + file_name)\n",
    "    for file_name in os.listdir(folderpath + \"images/labels\"):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            os.remove(folderpath + \"images/labels/\" + file_name)\n",
    "\n",
    "#     shutil.rmtree(folderpath + \"vectors/masks\")\n",
    "#     shutil.rmtree(folderpath + \"vectors/nm\")  #removing directories\n",
    "#     shutil.rmtree(folderpath + \"vectors/m\")\n",
    "\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "       try:\n",
    "           for gpu in gpus:\n",
    "               tf.config.experimental.set_memory_growth(gpu, True)\n",
    "           logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "           print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "       except RuntimeError as e:\n",
    "           print(e)\n",
    "            \n",
    "    print(\"Creating raster_masks...\")\n",
    "    raster_mask(raster_file, vector_file)\n",
    "    temp_dir = os.path.dirname(vector_file)\n",
    "    mask_file = os.path.join(temp_dir, \"masks\", \"mask_binary.tif\")\n",
    "\n",
    "    # Generates segmentation labels\n",
    "    out_dir = os.path.dirname(raster_file)\n",
    "    gen_seg_labels(out_width, raster_file, vector_file, mask_file, out_dir, True, True)\n",
    "    map_file = os.path.join(out_dir, \"map.txt\")\n",
    "    #map_files.append(map_file)\n",
    "        \n",
    "    img_1, meta10 = raster.load_image(\"../dataset/training/vectors/masks/mask_binary.png\")\n",
    "    show(img_1)\n",
    "    \n",
    "    create_seg_dataset(map_file, \"training\", 0)\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.list_files(training_data + \"images/*.jpg\", seed=SEED)\n",
    "    test_dataset = test_dataset.map(load_image_val, num_parallel_calls=AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(16)\n",
    "    \n",
    "    print(\"Evaluating on 2019-07_site03...\")\n",
    "    model.evaluate(test_dataset, \n",
    "                  callbacks=callback\n",
    "                  )\n",
    "    \n",
    "    #print(\"Evaluating on 2019-07_site03...\")\n",
    "\n",
    "# raster_files = [img_p + \"lap_2018-07_site1_120m_RGB_cc.tif\", \n",
    "#                 img_p + \"lap_2019-07_site03_120m_RGB_quick.tif\",\n",
    "#                 img_p + \"lap_2018-07_site05_120m_RGB_cc.tif\",\n",
    "#                 img_p + \"lap_2019-07_site06_120m_RGB_quick.tif\",\n",
    "#                 img_p + \"lap_2018-07_site04_120m_RGB_cc.tif\",\n",
    "#                 img_p + \"lap_2018-07_site06_120m_RGB_cc.tif\",\n",
    "#                 img_p + \"psc_2018-05_site01_120m_RGB_cc.tif\",\n",
    "#                 img_p + \"psc_2018-05_site11_120m_RGB.tif\",\n",
    "#                 img_p + \"psc_2018-05_site12_120m_RGB.tif\",\n",
    "#                 img_p + \"psc_2018-05_site8.tif\",\n",
    "#                 img_p + \"psc_2018-07_site08_120m_RGB.tif\",\n",
    "#                 img_p + \"psc_2018-07_site11_120m_RGB.tif\",\n",
    "#                 img_p + \"psc_2018-07_site10_120m_RGB.tif\",\n",
    "#                 img_p + \"psc_2018-07_site09_120m_RGB.tif\",\n",
    "#                 img_p + \"psc_2018-05_site13-14_120m_RGB.tif\",\n",
    "#                ]\n",
    "\n",
    "# vector_files = [vec_p + \"lap_2018-07_site01_labels_m-nm.shp\", \n",
    "#                 vec_p + \"lap_2019-07_site03_labels_m-nm.shp\", \n",
    "#                 vec_p + \"lap_2018-07_site05_120m_m-nm_dissolve.shp\",\n",
    "#                 vec_p + \"lap_2019-07_site06_120m_labels_m-nm.shp\",\n",
    "#                 vec_p + \"lap_2018-07_site04_labels_m-nm.shp\",\n",
    "#                 vec_p + \"lap_2018-07_site06_120m_RGB_m-nm.shp\",\n",
    "#                 vec_p + \"psc_2018-05_site01_120m_RGB_cc labels_m-nm.shp\",\n",
    "#                 vec_p + \"psc_2018-05_site11_120m_RGB_dissolved.shp\",\n",
    "#                 vec_p + \"psc_2018-05_site12_labels_m-nm.shp\",\n",
    "#                 vec_p + \"psc_2018-05_site8_labels_m-nm.shp\",\n",
    "#                 vec_p + \"psc_2018-07_site08_120m_RGB_labels_m-nm.shp\",\n",
    "#                 vec_p + \"psc_2018-07_site11_120m_RGB_m-nm.shp\",\n",
    "#                 vec_p + \"psc_2018-07_site_10_labels_m-nm.shp\",\n",
    "#                 vec_p + \"psc_201807_site9_mnm.shp\",\n",
    "#                 vec_p + \"psc_2018_05_site1314_120m_mnm.shp\",\n",
    "#                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(backbone, weight_file):\n",
    "    # For tensorboard\n",
    "    logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, update_freq='epoch')\n",
    "\n",
    "\n",
    "    # For more information about autotune:\n",
    "    # https://www.tensorflow.org/guide/data_performance#prefetching\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    print(f\"Tensorflow ver. {tf.__version__}\")\n",
    "\n",
    "    # For reproducibility\n",
    "    SEED = 42\n",
    "\n",
    "    # Data\n",
    "    training_data = \"../dataset/training/\"\n",
    "    #val_data = \"../dataset/validation/\"\n",
    "    \n",
    "    # 1Listing GPU info\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    # Hyperparams\n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 1000 # See https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
    "\n",
    "    # Creating and splitting dataset\n",
    "    DATASET_SIZE = len(glob(training_data + \"images/*.jpg\"))\n",
    "    print(f\"The Training Dataset contains {DATASET_SIZE} images.\")\n",
    "\n",
    "    TRAIN_SIZE = int(0.8 * DATASET_SIZE)\n",
    "    VAL_SIZE = int(0.2 * DATASET_SIZE)\n",
    "\n",
    "#     full_dataset = tf.data.Dataset.list_files(training_data + \"images/*.jpg\", seed=SEED)\n",
    "#     full_dataset = full_dataset.shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "#     train_dataset = full_dataset.take(TRAIN_SIZE)\n",
    "#     val_dataset = full_dataset.skip(TRAIN_SIZE)\n",
    "    \n",
    "#     # Creating dict pairs linking images and annotations\n",
    "#     train_dataset = train_dataset.map(parse_image)\n",
    "#     val_dataset = val_dataset.map(parse_image)\n",
    "\n",
    "#     # -- Train Dataset --# - https://stackoverflow.com/questions/49915925/output-differences-when-changing-order-of-batch-shuffle-and-repeat\n",
    "#     train_dataset = train_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "#     train_dataset = train_dataset.shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "#     train_dataset = train_dataset.repeat()\n",
    "#     train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "#     train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#     #-- Validation Dataset --#\n",
    "#     #for image, label in tfds.as_numpy(val_dataset):\n",
    "#      # print(type(image), type(label), label)\n",
    "    \n",
    "#     val_dataset = val_dataset.map(load_image_val, num_parallel_calls=AUTOTUNE)\n",
    "#     val_dataset = val_dataset.repeat()\n",
    "#     val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "#     val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.list_files(training_data + \"images/*.jpg\", seed=SEED)\n",
    "    test_dataset = test_dataset.map(parse_image)\n",
    "    test_dataset = test_dataset.map(load_image_val, num_parallel_calls=AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(16)\n",
    "    \n",
    "    # define model\n",
    "    model = sm.Unet(\n",
    "        #'resnet34',\n",
    "        #'vgg16', \n",
    "        backbone,\n",
    "        input_shape=(HEIGHT, WIDTH, N_CHANNELS), \n",
    "        encoder_weights='imagenet', \n",
    "        weights=weight_file, # for evaluation\n",
    "        encoder_freeze=True,    # only training decoder network\n",
    "        classes=NUM_CLASSES,\n",
    "        activation='softmax'\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        'Adam', \n",
    "        loss=LOSS_FUNC, \n",
    "        metrics=[sm.metrics.iou_score] #was giving score over 100 in later epochs before normalizing masks\n",
    "        #[tf.keras.metrics.MeanIoU(num_classes=2)]]\n",
    "    )\n",
    "#     # TODO research step sizes\n",
    "#     history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=1,\n",
    "#     steps_per_epoch=TRAIN_SIZE / BATCH_SIZE,\n",
    "#     validation_data=val_dataset,\n",
    "#     validation_steps= 0.2 * (VAL_SIZE / BATCH_SIZE),\n",
    "#     callbacks=[tensorboard_callback]\n",
    "#     )\n",
    "\n",
    "#     # Saving model\n",
    "#     #model.save_weights(\"unet_500_weights_vgg16.h5\")\n",
    "#     model.save_weights(weight_file)\n",
    "    \n",
    "    model.evaluate(\n",
    "            test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=tensorboard_callback,\n",
    "            )\n",
    "\n",
    "    # For reinstantiation\n",
    "    #model = keras.models.load_model(your_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densecrf(pred_mask, img, g_feats):\n",
    "    img = np.reshape(img, (256, 256, 3))\n",
    "    softmax = pred_mask.transpose((2, 0, 1))\n",
    "    unary = utils.unary_from_softmax(softmax)\n",
    "    \n",
    "    # The inputs should be C-continious -- we are using Cython wrapper\n",
    "    unary = np.ascontiguousarray(unary)\n",
    "    \n",
    "    d = dcrf.DenseCRF(img.shape[0] * img.shape[1], 2) # h * w, channels\n",
    "    d.setUnaryEnergy(unary)\n",
    "    \n",
    "    #gaussian penalizes small pieces of segmentation that are spatially isolated\n",
    "    d.addPairwiseEnergy(g_feats, compat=3,\n",
    "                    kernel=dcrf.DIAG_KERNEL,\n",
    "                    normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    \n",
    "    # This creates the color-dependent features --\n",
    "    # because the segmentation that we get from CNN are too coarse\n",
    "    # and we can use local color features to refine them\n",
    "    bi_feats = utils.create_pairwise_bilateral(sdims=(50, 50), schan=(20, 20, 20),\n",
    "                                   img=img, chdim=2)\n",
    "\n",
    "    d.addPairwiseEnergy(bi_feats, compat=10,\n",
    "                     kernel=dcrf.DIAG_KERNEL,\n",
    "                     normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "    \n",
    "    Q = d.inference(5)\n",
    "    res = np.argmax(Q, axis=0).reshape((img.shape[0], img.shape[1]))\n",
    "    return np.reshape(res, (256, 256, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(array, val_array):\n",
    "    assert array.shape == val_array.shape, \"Array and Validation Array have different sizes.\"\n",
    "    np.reshape(array, (HEIGHT, WIDTH))\n",
    "    np.reshape(val_array, (HEIGHT, WIDTH))\n",
    "    intersection = np.sum(array == val_array)\n",
    "    union = array.shape[0] * array.shape[1]\n",
    "    res = intersection / union\n",
    "    assert res <= 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, meta = raster.load_image(\"../dataset/testing/vectors/masks/mask_binary.tif\")\n",
    "# resampled, transform = raster.downsample_raster(img, 1/4)\n",
    "# fig, ax = plt.subplots(figsize=(6,6))\n",
    "# rasterio.plot.show(img, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(backbone, weight_file, raster_file):\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    print(f\"Tensorflow ver. {tf.__version__}\")\n",
    "\n",
    "    # For reproducibility\n",
    "    SEED = 42\n",
    "\n",
    "    # Relevant directories/files\n",
    "    image_dir = \"../dataset/testing/images/images\"\n",
    "    annotation_dir = \"../dataset/testing/annotations\"\n",
    "    label_dir = \"../dataset/testing/images/labels\"\n",
    "    out_dir = \"../dataset/testing/output\"\n",
    "    testing_data = \"../dataset/testing/\"\n",
    "    model_weights = weight_file\n",
    "\n",
    "    #Listing GPU info\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "       try:\n",
    "           for gpu in gpus:\n",
    "               tf.config.experimental.set_memory_growth(gpu, True)\n",
    "           logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "           print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "       except RuntimeError as e:\n",
    "           print(e)\n",
    "\n",
    "    # Hyperparams\n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 1000 # See https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
    "\n",
    "    model = sm.Unet(\n",
    "        #'vgg16', \n",
    "        backbone,\n",
    "        input_shape=(HEIGHT, WIDTH, N_CHANNELS), \n",
    "        encoder_weights='imagenet', \n",
    "        weights=model_weights,\n",
    "        encoder_freeze=True,    # only training decoder network\n",
    "        classes=NUM_CLASSES, \n",
    "        activation='sigmoid'\n",
    "    )\n",
    "\n",
    "    # Might be unnecessary\n",
    "    model.compile(\n",
    "        'Adam', \n",
    "        #loss=sm.losses.bce_jaccard_loss, \n",
    "        loss=LOSS_FUNC,\n",
    "        metrics=[sm.metrics.iou_score]\n",
    "    )\n",
    "\n",
    "    test_dataset = glob(image_dir + \"/*.tif\")\n",
    "    DATASET_SIZE = len(test_dataset)\n",
    "    tot_iou = 0 # for taking the mean iou of all the tiles at the end \n",
    "    \n",
    "    # CRF Pairwise energies:\n",
    "    # This potential penalizes small pieces of segmentation that are\n",
    "    # spatially isolated -- enforces more spatially consistent segmentations\n",
    "    g_feats = utils.create_pairwise_gaussian(sdims=(10, 10), shape=(HEIGHT, WIDTH))\n",
    "    \n",
    "    temp = os.path.basename(raster_file)\n",
    "    raster_name = temp.replace(\".tif\", \"\") # isolate name of ortho w/out extension (.tif)\n",
    "\n",
    "    \n",
    "    # Loop for inference\n",
    "    print(\"\\nStarting inference... \\n\")\n",
    "    for img_file in tqdm(test_dataset):\n",
    "        #tif_file = img_file.replace(\"jpg\", \"tif\") # \n",
    "\n",
    "        img = tf.io.read_file(img_file)\n",
    "        img = tf.image.decode_jpeg\n",
    "        img = np.asarray(Image.open(img_file)) / 255.0 # normalization not needed as we dont normalize the img for training\n",
    "        img = img[:,:,:3] # slice off A channel\n",
    "        img = img[np.newaxis, ...] # needs (batch_size, height, width, channels)\n",
    "        pred_mask = model.predict(img)[0]\n",
    "        #pred_mask = densecrf(pred_mask, img, g_feats) # shape: (256, 256, 2)  -> (256, 256, 1)\n",
    "        pred_mask = create_mask(pred_mask) # shape: (256, 256, 2)  -> (256, 256, 1)\n",
    "        pred_mask = 1 - pred_mask\n",
    "        pred_mask = pred_mask * 255\n",
    "        pred_mask = np.array(pred_mask).astype('uint8')  # should be binary (0, 255) values only \n",
    "        \n",
    "        # get filepaths of true_mask and predicted mask for specific tile\n",
    "        temp = os.path.basename(img_file)   # remove dir, -> \"tif-name_00_00.tif\"\n",
    "        temp = temp.replace(raster_name, \"\") # code at end of raster -> \"_00_00.tif\"\n",
    "        true_mask_fp =  label_dir + \"/mask_binary\" + temp # last bit is code: \"_01_23.tif\" for example \n",
    "        true_mask = np.asarray(Image.open(true_mask_fp))\n",
    "        true_mask = true_mask[:,:,:1] # slice off 3 channels\n",
    "        \n",
    "        # compare predicted to ground truth \"mask_binary\" files\n",
    "        tot_iou += IOU(pred_mask, true_mask)\n",
    "        \n",
    "        # Reading metadata from .tif\n",
    "        with rasterio.open(img_file) as src: # changed \"tif_file\" -> \"img_file\"\n",
    "            tif_meta = src.meta\n",
    "            tif_meta['count'] = 1\n",
    "\n",
    "        # Writing prediction mask as a .tif using extracted metadata\n",
    "        mask_file = img_file.replace(\"images/images\", \"output\") # changed \"tif_file\" -> \"img_file\"\n",
    "        with rasterio.open(mask_file, \"w\", **tif_meta) as dest:\n",
    "            # Rasterio needs [bands, width, height]\n",
    "            pred_mask = np.rollaxis(pred_mask, axis=2)\n",
    "            dest.write(pred_mask)\n",
    "  \n",
    "    print(\"Mean IOU:\", tot_iou/DATASET_SIZE ) # display iou\n",
    "    print(\"Merging tiles (to create mask ortho)...\")\n",
    "    call = \"gdal_merge.py -o \" + testing_data + \"ortho_mask.tif \" + \" \" + out_dir + \"/*\"\n",
    "    print(call)\n",
    "    subprocess.call(call, shell=True)\n",
    "    \n",
    "    return tot_iou/DATASET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_optimized(backbone, weight_file):\n",
    "    '''\n",
    "    Note: This version of test does not work yet. It is optimized to be very efficient and works well for inference on .jpg files.\n",
    "    It lacks the capabilities to link the output predictions to the input .jpgs since the filenames are lost when in the tf.dataset\n",
    "    we map the parse image function. As a result, we need to somehow modify this dataset to retain filename information so we can use it\n",
    "    to link the output prediction to the input image and its corresponding .tif file, which will be used to write the geospatial info to\n",
    "    the prediction.\n",
    "\n",
    "    Initial ideas would be to modify the parse image function and related functions to save filename info, and use this to link the images\n",
    "    in the prediction stage by replacing .jpg with .tif in the filename.\n",
    "    '''\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    print(f\"Tensorflow ver. {tf.__version__}\")\n",
    "\n",
    "    # For reproducibility\n",
    "    SEED = 42\n",
    "\n",
    "    # Relevant directories/files\n",
    "    images = \"../dataset/testing/images\"\n",
    "    annotations = \"../dataset/testing/annotations\"\n",
    "    testing_data = \"../dataset/testing/\"\n",
    "    #model_weights = \"unet_500_weights_vgg16.h5\"\n",
    "    model_weights = weight_file\n",
    "\n",
    "    # Listing GPU info\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "    # Hyperparams\n",
    "    BATCH_SIZE = 16\n",
    "    BUFFER_SIZE = 1000 # See https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
    "\n",
    "    model = sm.Unet(\n",
    "        'resnet34', \n",
    "        input_shape=(HEIGHT, WIDTH, N_CHANNELS), \n",
    "        encoder_weights='imagenet', \n",
    "        weights=model_weights,\n",
    "        encoder_freeze=True,    # only training decoder network\n",
    "        classes=2, \n",
    "        activation='softmax'\n",
    "    )\n",
    "\n",
    "    # Might be unnecessary\n",
    "    model.compile(\n",
    "        'Adam', \n",
    "        loss=LOSS_FUNC, \n",
    "        metrics=[sm.metrics.iou_score]\n",
    "    )\n",
    "\n",
    "    test_dataset = tf.data.Dataset.list_files(testing_data + \"images/*.jpg\", seed=SEED)\n",
    "    test_dataset = test_dataset.map(parse_image)\n",
    "    test_dataset = test_dataset.map(load_image_val, num_parallel_calls=AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    image_data = []\n",
    "    annotation_data = []\n",
    "    \n",
    "    '''\n",
    "    for img_file in tqdm(os.listdir(images)): \n",
    "        annotation_file = \"annotation_\" + img_file.split('_')[1]\n",
    "        img_file = os.path.join(images, img_file)\n",
    "        ann_file = os.path.join(annotations, annotation_file)\n",
    "        image = np.array(Image.open(img_file))\n",
    "        annotation = np.array(Image.open(ann_file))\n",
    "        image_data.append(image)\n",
    "        annotation_data.append(annotation)\n",
    "    '''\n",
    "\n",
    "\n",
    "    #prediction = model.predict(test_dataset, steps=1)\n",
    "    #print(type(prediction))\n",
    "\n",
    "\n",
    "    #display([first_image[0], first_mask[0], create_mask(first_pred_mask)])\n",
    "\n",
    "    #pred_mask = model.predict(test_dataset)\n",
    "    #display([image[0], mask[0], create_mask(pred_mask)])\n",
    "\n",
    "    show_predictions(model=model, dataset=test_dataset, num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_setup(raster_files, vector_files, out_width):\n",
    "    # Uses raster and vector file to create dataset for training\n",
    "    data_files = zip(raster_files, vector_files)\n",
    "    map_files = [] \n",
    "\n",
    "    for raster_file, vector_file in data_files:\n",
    "        # Generates raster masks\n",
    "        print(\"Creating raster_masks...\")\n",
    "        raster_mask(raster_file, vector_file)\n",
    "        temp_dir = os.path.dirname(vector_file)\n",
    "        mask_file = os.path.join(temp_dir, \"masks\", \"mask_binary.tif\")\n",
    "\n",
    "        # Generates segmentation labels\n",
    "        out_dir = os.path.dirname(raster_file)\n",
    "        gen_seg_labels(out_width, raster_file, vector_file, mask_file, out_dir, True, True)\n",
    "        map_file = os.path.join(out_dir, \"map.txt\")\n",
    "        map_files.append(map_file)\n",
    "\n",
    "    # Creating dataset to train UNet\n",
    "    create_seg_dataset(map_files, \"training\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_setup(raster_files, out_width):\n",
    "    out_dir = \"../dataset/testing/output\"\n",
    "    test_dir = \"../dataset/testing\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    print(\"\\nTiling rasters...\")\n",
    "    for raster_file in raster_files:\n",
    "        tile_raster(out_width, raster_file, test_dir, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_setup_iou(raster_file, vector_file, out_width):\n",
    "    \"\"\" \n",
    "    Setup for displaying mean iou after testing, \n",
    "    expects directories to be present:\n",
    "                                        'testing/images'       : with test rasters inside\n",
    "                                        'testing/vectors'      : with test vectors inside\n",
    "                                        'testing/images/images': for retiled rasters (.tif)\n",
    "                                        'testing/vectors/masks': for retiled true_masks (.jpg)\n",
    "                                        \n",
    "    Will only work with ONE image at a time, also make sure to clear directories after use.\n",
    "    \"\"\"\n",
    "    \n",
    "    out_dir = \"../dataset/testing/output\"\n",
    "    test_dir = \"../dataset/testing\"\n",
    "    mask_file = test_dir + \"/vectors/masks/mask_binary.tif\"\n",
    "    img_dir =  test_dir + \"/images\"\n",
    "    \n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    #for raster_file, vector_file in zip(raster_files, vector_files):\n",
    "    print(\"Creating Mask(s)...\") # creates 'mask_binary.tif;' in testing/vectors/masks \n",
    "    raster_mask(raster_file, vector_file)\n",
    "        \n",
    "        # creates labels and writes them to testing/images/labels\n",
    "    gen_seg_labels(out_width, raster_file, vector_file, mask_file, img_dir, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(img, i):\n",
    "    for x in range(i):\n",
    "        rows, cols , _channels = map(int, img.shape)\n",
    "        img = cv2.pyrDown(img, dstsize=(cols//2, rows//2))\n",
    "    return img\n",
    "\n",
    "def write_downsampled(img_path, i, out_path):\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"path {img_path} does not exist\")\n",
    "        return\n",
    "    img = cv2.imread(img_path)\n",
    "    img = downsample(img, i)\n",
    "    cv2.imwrite(out_path, img)\n",
    "    return\n",
    "# print(img.shape)\n",
    "# img = downsample(img, 5)\n",
    "# print(img.shape)\n",
    "# cv2.imwrite(\"downsampled.png\", img)\n",
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_tone():\n",
    "    framerate = 4410\n",
    "    play_time_seconds = 3\n",
    "\n",
    "    t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "    audio_data = np.sin(2*np.pi*300*t) + np.sin(2*np.pi*240*t)\n",
    "    Audio(audio_data, rate=framerate, autoplay=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize arguments\n",
    "out_width = \"256\"\n",
    "all_raster_files = [\n",
    "#                 \"lap_2018-07_site1_120m_RGB_cc.tif\", \n",
    "#                  \"lap_2019-07_site03_120m_RGB_quick.tif\",\n",
    "#                 \"lap_2018-07_site05_120m_RGB_cc.tif\",\n",
    "#                 \"lap_2019-07_site06_120m_RGB_quick.tif\",\n",
    "#                 \"lap_2018-07_site04_120m_RGB_cc.tif\",\n",
    "#                 \"lap_2018-07_site06_120m_RGB_cc.tif\",\n",
    "#                  \"psc_2018-05_site01_120m_RGB_cc.tif\",\n",
    "                \"psc_2018-05_site11_120m_RGB.tif\",\n",
    "                \"psc_2018-05_site12_120m_RGB.tif\",\n",
    "#                 \"psc_2018-05_site8.tif\",\n",
    "#                 \"psc_2018-07_site08_120m_RGB.tif\",\n",
    "#                 \"psc_2018-07_site11_120m_RGB.tif\",\n",
    "#                 \"psc_2018-07_site10_120m_RGB.tif\",\n",
    "#                 \"psc_2018-07_site09_120m_RGB.tif\",\n",
    "#                 \"psc_2018-05_site13-14_120m_RGB.tif\",\n",
    "               ]\n",
    "\n",
    "all_vector_files = [\n",
    "#                 \"lap_2018-07_site01_labels_m-nm.shp\", \n",
    "#                 \"lap_2019-07_site03_labels_m-nm.shp\", \n",
    "#                 \"lap_2018-07_site05_120m_m-nm_dissolve.shp\",\n",
    "#                 \"lap_2019-07_site06_120m_labels_m-nm.shp\",\n",
    "#                 \"lap_2018-07_site04_labels_m-nm.shp\",\n",
    "#                 \"lap_2018-07_site06_120m_RGB_m-nm.shp\",\n",
    "#                 \"psc_2018-05_site01_120m_RGB_cc labels_m-nm.shp\",\n",
    "                \"psc_2018-05_site11_120m_RGB_dissolved.shp\",\n",
    "                \"psc_2018-05_site12_labels_m-nm.shp\",\n",
    "#                 \"psc_2018-05_site8_labels_m-nm.shp\",\n",
    "#                 \"psc_2018-07_site08_120m_RGB_labels_m-nm.shp\",\n",
    "#                 \"psc_2018-07_site11_120m_RGB_m-nm.shp\",\n",
    "#                 \"psc_2018-07_site_10_labels_m-nm.shp\",\n",
    "#                 \"psc_201807_site9_mnm.shp\",\n",
    "#                 \"psc_2018_05_site1314_120m_mnm.shp\",\n",
    "               ]\n",
    "\n",
    "weight_file = \"../dataset/training/weights/08_10_vgg16_200_full_weight.h5\"\n",
    "backbone = \"vgg16\"\n",
    "\n",
    "test_raster_files = [\"../dataset/testing/images/\" + img for img in all_raster_files]\n",
    "test_vector_files = [\"../dataset/testing/vectors/\" + vec for vec in all_vector_files]\n",
    "\n",
    "train_vector_files = [\"../dataset/training/images/\" + img for img in all_raster_files]\n",
    "train_vector_files = [\"../dataset/training/vectors/\" + vec for vec in all_vector_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_test_dir(test_dir, images=False, masks=False, output=False):\n",
    "    \"\"\"\n",
    "    deletes file in test_dir based on args passed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_dir: str\n",
    "        path to test_dir (usually \"../dataset/testing/\")\n",
    "    images: bool\n",
    "        deletes all files in \"test_dir/images/images\", AND \"test_dir/images/labels\"\n",
    "    masks: bool \n",
    "        deletes directories: \"test_dir/m\", \"test_dir/nm\", \"test_dir/masks\"\n",
    "    output:\n",
    "        deletes all files in \"test_dir/output\", AND \"test_dir/ortho_mask.tif\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    def handleError(func, path, exc_info): # for shutil.rmtree\n",
    "        print(f\"{path} caused error when deleting\")\n",
    "        pass\n",
    "    \n",
    "    if images:\n",
    "        for file_name in os.listdir(test_dir + \"images/images\"):\n",
    "            os.remove(test_dir + \"images/images/\" + file_name)\n",
    "        for file_name in os.listdir(test_dir + \"images/labels\"):\n",
    "            os.remove(test_dir + \"images/labels/\" + file_name)\n",
    "    \n",
    "    if masks:\n",
    "        shutil.rmtree(test_dir + \"vectors/masks\", onerror=handleError) \n",
    "        shutil.rmtree(test_dir + \"vectors/nm\", onerror=handleError)  #removng directories\n",
    "        shutil.rmtree(test_dir + \"vectors/m\", onerror=handleError)\n",
    "        \n",
    "    if output:\n",
    "        for file_name in os.listdir(test_dir + \"output\"):\n",
    "            os.remove(test_dir + \"output/\" + file_name)\n",
    "        if os.path.exists(test_dir + \"ortho_mask.tif\"):\n",
    "            os.remove(test_dir + \"ortho_mask.tif\")\n",
    "        else:\n",
    "            print(\"No ortho_mask to delete\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights(test_raster_files, test_vector_files, full_weight_files, ds_factor, display=False):\n",
    "    \"\"\"\n",
    "    Tests multiple weight_files on a set of images and their corresponding vectors.\n",
    "    \n",
    "    Creates a directory in \"../dataset/testing/runs/MM-DD-YY_hr-min\", where directories\n",
    "    for each weight are created. Each weight directory has a text file with iou scores \n",
    "    for each image as well as downsampled images for each raster tested on.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raster_files: list[str]\n",
    "        list of raster filepaths, MUST be in \"../dataset/testing/\", order should match vector_files (.tif)\n",
    "    vector_files: list[str]\n",
    "        list of vector filepaths, MUST be in \"../dataset/testing/\" (.shp)\n",
    "    full_weight_files: list[str]\n",
    "        list of weight filepaths (.h5)\n",
    "    ds_factor: int\n",
    "        how many times to recursively downsample img using cv2.pyrDown, each iteration halves size\n",
    "    display: bool\n",
    "        show output image after each prediction by each weight\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    def write_iou_scores(run_dir, weight_files, iou_scores):\n",
    "        # save \"iou.txt\" to each \"run_dir/weight/\" and save \"run_dir/all_iou_scores.txt\"\n",
    "        with open(run_dir + \"all_iou_scores.txt\", 'w') as f:\n",
    "            for weight_list in iou_scores:\n",
    "                for tup in weight_list:\n",
    "                    if type(tup) != tuple:\n",
    "                        f.write(tup + \"\\n\")\n",
    "                    else:\n",
    "                        f.write(tup[0] + \" iou: \")\n",
    "                        f.write(str(tup[1]) + \"\\n\")\n",
    "                f.write(\"-------------\\n\")\n",
    "        \n",
    "        for i, weight in enumerate(weight_files):\n",
    "            temp = os.path.basename(weight) # remove dir + extension\n",
    "            bare_weight = temp.replace(\".h5\", \"\")   \n",
    "            weight_dir = run_dir + bare_weight + \"/\"# dir for each weight \n",
    "            iou_scores[i].insert(0, \"(test_image, iou_score) for weight:\") # file header\n",
    "            with open(weight_dir + 'iou_scores.txt', 'w') as f:\n",
    "                for tup in iou_scores[i]:\n",
    "                    if type(tup) != tuple:\n",
    "                        f.write(tup + \"\\n\")\n",
    "                    else:\n",
    "                        f.write(tup[0] + \" iou: \")\n",
    "                        f.write(str(tup[1]) + \"\\n\")\n",
    "                f.write(\"-------------\\n\")\n",
    "\n",
    "    ############################################# setup\n",
    "    print(f\"There are {len(full_weight_files)} weight files\")\n",
    "    print(f\"They will be tested on {len(test_raster_files)} images\\n\\n\")\n",
    "    test_dir = \"../dataset/testing/\"\n",
    "    ortho_path = test_dir + \"ortho_mask.tif\"\n",
    "    iou_scores = [[x] for x in full_weight_files] # list of iou scores where first entry is weight used\n",
    "    testing_imgs = test_dir + \"images/\"\n",
    "    run_dir =  test_dir + \"runs/\" + time.strftime('%m-%d-%y_%I-%M%p/') # dir with date_time\n",
    "    if os.path.exists(run_dir):\n",
    "        print(f\"error: run_dir: {run_dir} already exists\")\n",
    "        return\n",
    "    else:\n",
    "        os.system(\"mkdir \" + run_dir)\n",
    "        \n",
    "    for w in full_weight_files: # mk dir for each weight file to store downsampled imgs/iou.txt\n",
    "        temp = os.path.basename(w) # remove dir + extension\n",
    "        bare_weight = temp.replace(\".h5\", \"\") \n",
    "        if os.path.exists(run_dir + bare_weight):\n",
    "            print(f\"error: run_dir/weight: {run_dir + babre_weight} already exists\")\n",
    "        else: \n",
    "            os.system(\"mkdir \" + run_dir + bare_weight)\n",
    "            print(\"mkdir \" + run_dir + bare_weight)\n",
    "    \n",
    "    if os.path.exists(ortho_path): # remove old output image\n",
    "        os.remove(\"../dataset/testing/ortho_mask.tif\")  \n",
    "    ############################################# end setup\n",
    "    \n",
    "    for raster_file, vector_file in zip(test_raster_files, test_vector_files):\n",
    "        test_setup_iou(raster_file, vector_file, out_width) # tile image and make true masks\n",
    "        temp = os.path.basename(raster_file)\n",
    "        raster_name = temp.replace(\".tif\", \".png\") # remove directory and change to \"img.png\"\n",
    "        \n",
    "        for i, weight in enumerate(full_weight_files):\n",
    "            temp = os.path.basename(weight) # remove dir + extension\n",
    "            bare_weight = temp.replace(\".h5\", \"\")\n",
    "            weight_dir = run_dir + bare_weight + \"/\"\n",
    "            iou = test(backbone, weight, raster_file) # generate \"../dataset/testing/ortho_mask.tif\"\n",
    "            \n",
    "            write_downsampled(ortho_path, ds_factor, weight_dir + raster_name) #save ortho_mask to weight_dir\n",
    "            assert iou_scores[i][0] == weight # check that appending correct list\n",
    "            iou_scores[i].append((raster_file, iou)) # append raster_file, and iou to list\n",
    "            \n",
    "            if display: # show output mask\n",
    "                img, meta = raster.load_image(ortho_path)\n",
    "                resampled, transform = raster.downsample_raster(img, 1/4)\n",
    "                fig, ax = plt.subplots(figsize=(6,6))\n",
    "                rasterio.plot.show(resampled, ax=ax)\n",
    "            clean_test_dir(test_dir, output=True) # remove output data that is unique to weight_file\n",
    "        \n",
    "        mask_path = run_dir + \"binary_mask_\" + raster_name\n",
    "        write_downsampled(test_dir + \"vectors/masks/mask_binary.tif\", ds_factor, mask_path)\n",
    "        clean_test_dir(test_dir, images=True, masks=True) # remove prior raster tiling data \n",
    "    # save an \"iou.txt\" file to each \"run_dir/weight/\" and save \"run_dir/full_iou.txt\" \n",
    "    write_iou_scores(run_dir, full_weight_files, iou_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Mask(s)...\n",
      "Splitting vectors...\n",
      "Creating mangrove files in ../dataset/testing/vectors/m\n",
      "Joined 1 mangrove polygons.\n",
      "Creating nonmangrove files in ../dataset/testing/vectors/nm\n",
      "Joined 1 nonmangrove polygons.\n",
      "Reading shapefile...\n",
      "Creating masks...\n",
      "Saving masks...\n",
      "../dataset/testing/vectors/masks\n",
      "Done.\n",
      "\n",
      "Executing GDAL calls...\n",
      "gdal_retile.py -ps 256 256 -targetDir ../dataset/testing/images/images ../dataset/testing/images/lap_2019-07_site03_120m_RGB_quick.tif\n",
      "gdal_retile.py -ps 256 256 -targetDir ../dataset/testing/images/labels ../dataset/testing/vectors/masks/mask_binary.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing undersized tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3782/3782 [00:07<00:00, 536.36it/s]\n",
      "100%|| 2985/2985 [00:00<00:00, 1741064.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 2985\n",
      "Number of Labels: 2985\n",
      "Creating Map...\n",
      "Done.\n",
      "Tensorflow ver. 2.2.0\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4d84a1ee6363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_setup_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raster_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vector_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_width\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tile image/mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_raster_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# run test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# show test result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-4fffa6bbd448>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(backbone, weight_file, raster_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mencoder_freeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# only training decoder network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/segmentation_models/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_KERAS_MODELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_KERAS_UTILS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/segmentation_models/models/unet.py\u001b[0m in \u001b[0;36mUnet\u001b[0;34m(backbone_name, input_shape, classes, activation, weights, encoder_weights, encoder_freeze, encoder_features, decoder_block_type, decoder_filters, decoder_use_batchnorm, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/segmentation_models/backbones/backbones_factory.py\u001b[0m in \u001b[0;36mget_backbone\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/classification_models/models_factory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mmodules_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mnew_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m                       \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                       name='block1_conv1')(img_input)\n\u001b[0m\u001b[1;32m    113\u001b[0m     x = layers.Conv2D(64, (3, 3),\n\u001b[1;32m    114\u001b[0m                       \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     return op(\n\u001b[0;32m-> 1068\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[0;32m--> 296\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    713\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m    714\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RandomUniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         tld.op_callbacks, shape, \"seed\", seed, \"seed2\", seed2, \"dtype\", dtype)\n\u001b[0m\u001b[1;32m    716\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Run Testing\n",
    "if os.path.exists(\"../dataset/testing/ortho_mask.tif\"): # remove old output image\n",
    "    os.remove(\"../dataset/testing/ortho_mask.tif\")\n",
    " \n",
    "test_setup_iou(test_raster_files[0], test_vector_files[0], out_width) # tile image/mask\n",
    "test(backbone, weight_file, test_raster_files[0]) # run test\n",
    "\n",
    "# show test result  \n",
    "img, meta = raster.load_image(\"../dataset/testing/ortho_mask.tif\")\n",
    "resampled, transform = raster.downsample_raster(img, 1/4)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "rasterio.plot.show(img, ax=ax)\n",
    "play_tone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 weight files\n",
      "They will be tested on 2 images\n",
      "\n",
      "\n",
      "mkdir ../dataset/testing/runs/08-21-20_11-10PM/08_10_vgg16_200_full_weight\n",
      "mkdir ../dataset/testing/runs/08-21-20_11-10PM/08_12_vgg16_350_full_weight-Copy1\n",
      "Creating Mask(s)...\n",
      "Splits exist, skipping splitting...\n",
      "Reading shapefile...\n",
      "Creating masks...\n",
      "Saving masks...\n",
      "../dataset/testing/vectors/masks\n",
      "Done.\n",
      "\n",
      "Executing GDAL calls...\n",
      "gdal_retile.py -ps 256 256 -targetDir ../dataset/testing/images/images ../dataset/testing/images/psc_2018-05_site11_120m_RGB.tif\n",
      "gdal_retile.py -ps 256 256 -targetDir ../dataset/testing/images/labels ../dataset/testing/vectors/masks/mask_binary.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing undersized tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13950/13950 [00:34<00:00, 407.86it/s]\n",
      "100%|| 10998/10998 [00:00<00:00, 1875542.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 10998\n",
      "Number of Labels: 10998\n",
      "Creating Map...\n",
      "Done.\n",
      "Tensorflow ver. 2.2.0\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-c31b28744e4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 ]\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtest_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_raster_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vector_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_weight_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-89-5a91c36d2380>\u001b[0m in \u001b[0;36mtest_weights\u001b[0;34m(test_raster_files, test_vector_files, full_weight_files, ds_factor, display)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mbare_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mweight_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbare_weight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0miou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraster_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# generate \"../dataset/testing/ortho_mask.tif\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mwrite_downsampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mortho_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mraster_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#save ortho_mask to weight_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-b034c68bd1e0>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(backbone, weight_file, raster_file)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mencoder_freeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# only training decoder network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/segmentation_models/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_KERAS_MODELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_KERAS_UTILS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/segmentation_models/models/unet.py\u001b[0m in \u001b[0;36mUnet\u001b[0;34m(backbone_name, input_shape, classes, activation, weights, encoder_weights, encoder_freeze, encoder_features, decoder_block_type, decoder_filters, decoder_use_batchnorm, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/segmentation_models/backbones/backbones_factory.py\u001b[0m in \u001b[0;36mget_backbone\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/classification_models/models_factory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mmodules_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mnew_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/keras_applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                       \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                       \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                       name='block4_conv1')(x)\n\u001b[0m\u001b[1;32m    150\u001b[0m     x = layers.Conv2D(512, (3, 3),\n\u001b[1;32m    151\u001b[0m                       \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     return op(\n\u001b[0;32m-> 1068\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[0;32m--> 296\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_tensorflow/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,256,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "# Run testing for comparing weights\n",
    "ds_factor = 5\n",
    "w_dir = \"../dataset/training/weights/\"\n",
    "full_weight_files = [\n",
    "#                 w_dir + \"unet_500_weights_vgg16.h5\",\n",
    "                w_dir + \"08_10_vgg16_200_full_weight.h5\",\n",
    "                w_dir + \"08_12_vgg16_350_full_weight-Copy1.h5\",\n",
    "                ]\n",
    "\n",
    "test_weights(test_raster_files, test_vector_files, full_weight_files, ds_factor, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow ver. 2.2.0\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "The Training Dataset contains 2985 images.\n",
      "187/187 [==============================] - 30s 161ms/step - loss: 0.6777 - iou_score: 0.2503\n"
     ]
    }
   ],
   "source": [
    "#Run Training\n",
    "#train_setup(raster_files, vector_files, out_width)\n",
    "train(backbone, weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     TRAIN = False\n",
    "#     TEST = False\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description=\"UNet Training and Inference Script (Note: order of rasters and vectors must correspond to one another)\")\n",
    "#     parser.add_argument(\"--width\",help = \"Width of output tiles\")\n",
    "#     parser.add_argument(\"--input_rasters\", nargs='*', help = \"space separated input orthomosaic (.tif)\")\n",
    "#     parser.add_argument(\"--input_vectors\", nargs='*', help = \"space separated input labels (.shp)\")\n",
    "#     parser.add_argument(\"--train\", action='store_true', help = \"training UNet\")\n",
    "#     parser.add_argument(\"--test\", action='store_true', help = \"testing UNet\")\n",
    "#     parser.add_argument(\"--weights\", help = \"path to weight file, either to save or use (.h5)\")\n",
    "#     parser.add_argument(\"--backbone\", help = \"segmentation model backbone, ex: resnet34, vgg16, etc.\")\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     # Parsing arguments\n",
    "#     if args.width:\n",
    "#         out_width = args.width\n",
    "#     else:\n",
    "#         print(\"Need to specify width, exiting.\")\n",
    "#         exit()\n",
    "#     if args.input_rasters:\n",
    "#         raster_files = args.input_rasters\n",
    "#     else:\n",
    "#         # Always needs a raster\n",
    "#         print(\"Need to specify raster file, exiting.\")\n",
    "#         exit()\n",
    "#     if args.input_vectors:\n",
    "#         vector_files = args.input_vectors\n",
    "#     else:\n",
    "#         # Requires vector labes for training, not inference\n",
    "#         if args.train:\n",
    "#             print(\"Need to specify input vector, exiting.\")\n",
    "#             exit()\n",
    "#     if args.train and args.test:\n",
    "#         print(\"Can't train and test at the same time... exiting.\")\n",
    "#         exit()\n",
    "#     elif args.train:\n",
    "#         TRAIN = True\n",
    "#     elif args.test:\n",
    "#         TEST = True\n",
    "#     if args.weights:\n",
    "#         weight_file = args.weights\n",
    "#     else:\n",
    "#         print(\"Need weight file, exiting.\")\n",
    "#         exit()\n",
    "#     if args.backbone:\n",
    "#         backbone = args.backbone\n",
    "#     else:\n",
    "#         print(\"Need to specify backbone, exiting.\")\n",
    "#         exit()\n",
    "\n",
    "#     # Selecting mode\n",
    "#     if TRAIN: \n",
    "#         train_setup(raster_files, vector_files, out_width)\n",
    "#         train(backbone, weight_file)\n",
    "#     if TEST:\n",
    "#         test_setup(raster_files, out_width)\n",
    "#         test(backbone, weight_file)\n",
    "#         #test_optimized(backbone, weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all training/images, /images/images, /images/labels, images/masks, \n",
    "#images/m, images/nm, anotations\n",
    "\n",
    "#delete all files with extension\n",
    "folderpath = \"../dataset/training/\"\n",
    "for file_name in os.listdir(folderpath + \"images/images\"):\n",
    "    if file_name.endswith('.jpg'):\n",
    "        os.remove(folderpath + \"images/images/\" + file_name)\n",
    "for file_name in os.listdir(folderpath + \"images\"):\n",
    "    if file_name.endswith('.jpg'):\n",
    "        os.remove(folderpath + \"images/\" + file_name)\n",
    "for file_name in os.listdir(folderpath + \"images/labels\"):\n",
    "    if file_name.endswith('.jpg'):\n",
    "        os.remove(folderpath + \"images/labels/\" + file_name)\n",
    "\n",
    "shutil.rmtree(folderpath + \"vectors/masks\")\n",
    "shutil.rmtree(folderpath + \"vectors/nm\")  #removng directories\n",
    "shutil.rmtree(folderpath + \"vectors/m\")\n",
    "shutil.rmtree(\"../dataset/testing/output\")\n",
    "shutil.rmtree(\"../dataset/testing/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_test_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-01abee75488b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#delete testing masks/images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclean_test_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../dataset/testing/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_test_dir' is not defined"
     ]
    }
   ],
   "source": [
    "#delete testing masks/images\n",
    "clean_test_dir(\"../dataset/testing/\", images=True, masks=True, output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_tensorflow",
   "language": "python",
   "name": "conda-env-py37_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
