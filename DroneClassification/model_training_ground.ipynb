{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import gc\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from data import MemmapDataset\n",
    "from models import *\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchgeo.models import resnet18, resnet50, get_weight\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset containing 680079 images loaded.\n",
      "Using CUDA device.\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "DATA_SPLIT = 0.90\n",
    "INIT_LR = 0.005\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "INPUT_IMAGE_SIZE = 224\n",
    "THRESHOLD = 0.5\n",
    "LOSS = JaccardLoss()\n",
    "\n",
    "# define the path to each directory\n",
    "BASE_DIR = \"C:\\\\Users\\\\gwrye\\\\OneDrive\\\\Desktop\\\\Drone_Dataset\"\n",
    "IMAGE_DIR = BASE_DIR + \"\\\\dataset_images.npy\"\n",
    "LABEL_DIR = BASE_DIR + \"\\\\dataset_labels.npy\"\n",
    "\n",
    "dataset = MemmapDataset(np.load(IMAGE_DIR, 'r'), np.load(LABEL_DIR, 'r'))\n",
    "print(f\"Dataset containing {len(dataset)} images loaded.\")\n",
    "\n",
    "# Setup the device to be used for training and evaluation\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "    print(\"Using Apple Metal Performance Shaders (MPS) device.\\n\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "    print(\"WARNING: No GPU found. Defaulting to CPU.\")\n",
    "\n",
    "trainDS, testDS = dataset.split(0.9)                           \n",
    "# calculate steps per epoch for training and test set #config\n",
    "TRAIN_STEPS = len(trainDS) // BATCH_SIZE\n",
    "TEST_STEPS = len(testDS) // BATCH_SIZE\n",
    "\n",
    "# create the training and test data loaders #config\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "                         batch_size=BATCH_SIZE)\n",
    "testLoader = DataLoader(testDS, shuffle=False,\n",
    "                        batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "del trainDS, testDS, dataset\n",
    "\n",
    "# Training Functions\n",
    "def train(model, trainLoader : DataLoader, testLoader : DataLoader, lossFunc, NUM_EPOCHS=NUM_EPOCHS, print_all_epochs = False):\n",
    "  opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "  # loop over epochs #config\n",
    "  print(\"[INFO] training the network...\")\n",
    "  training_loss = []\n",
    "  all_metrics = []\n",
    "\n",
    "  for e in tqdm(range(NUM_EPOCHS)):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "    totalTrainLoss = 0\n",
    "\n",
    "    # loop over the training set\n",
    "    for (i, (x, y)) in enumerate(trainLoader):\n",
    "      # send the input to the device\n",
    "      x = x.to(DEVICE)\n",
    "      y = y.to(DEVICE).float()\n",
    "      # perform a forward pass and calculate the training loss\n",
    "      pred = model(x)\n",
    "      if isinstance(pred, tuple):\n",
    "        pred = pred[0]\n",
    "      loss = lossFunc(pred, y)\n",
    "\n",
    "      # first, zero out any previously accumulated gradients, then\n",
    "      # perform backpropagation, and then update model parameters\n",
    "      opt.zero_grad()\n",
    "      loss.backward()\n",
    "      opt.step()\n",
    "\n",
    "      # add the loss to the total training loss so far\n",
    "      totalTrainLoss += loss.item()\n",
    "    # calculate the average training\n",
    "    avgTrainLoss = totalTrainLoss / TRAIN_STEPS\n",
    "    training_loss.append(avgTrainLoss)\n",
    "\n",
    "    # Evaluate on test dataset\n",
    "    metrics = evaluate(model, testLoader, lossFunc)\n",
    "    all_metrics.append(metrics)\n",
    "    avgTestLoss = metrics['Loss']\n",
    "\n",
    "    if (e + 1) % 5 == 0 or e == 0 or print_all_epochs:\n",
    "      # print the model training and validation information\n",
    "      print(\"EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS)) #config\n",
    "      print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
    "          avgTrainLoss, avgTestLoss))\n",
    "      print(\"\\nValidation Metrics:\")\n",
    "      for k, v in metrics.items():\n",
    "          if k != 'Loss':\n",
    "            print(f\"{k}: {v}\")\n",
    "      print(\"\\n\")\n",
    "  return training_loss, all_metrics\n",
    "\n",
    "def evaluate(model: nn.Module, dataloader: DataLoader, loss_func):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_TP = 0\n",
    "    total_FP = 0\n",
    "    total_FN = 0\n",
    "    total_TN = 0\n",
    "    total_landmass_captured = 0\n",
    "    total_landmass_actual = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE).float()\n",
    "            \n",
    "            pred = model(x)\n",
    "            if isinstance(pred, tuple):\n",
    "                pred = pred[0]\n",
    "            loss = loss_func(pred, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred = torch.sigmoid(pred).view(-1)\n",
    "            y = y.view(-1)\n",
    "            \n",
    "            TP = (pred * y).sum().item()\n",
    "            FP = ((1 - y) * pred).sum().item()\n",
    "            FN = (y * (1 - pred)).sum().item()\n",
    "            TN = ((1 - y) * (1 - pred)).sum().item()\n",
    "        \n",
    "            total_TP += TP\n",
    "            total_FP += FP\n",
    "            total_FN += FN\n",
    "            total_TN += TN\n",
    "\n",
    "            total_landmass_actual += y.sum().item()\n",
    "            total_landmass_captured += pred.sum().item()\n",
    "\n",
    "    total_landmass_captured = total_landmass_captured / total_landmass_actual if total_landmass_actual > 0 else 0\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    precision = total_TP / (total_TP + total_FP) if (total_TP + total_FP) > 0 else 0\n",
    "    recall = total_TP / (total_TP + total_FN) if (total_TP + total_FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    iou = total_TP / (total_TP + total_FP + total_FN) if (total_TP + total_FP + total_FN) > 0 else 0\n",
    "    accuracy = (total_TP + total_TN) / (total_TP + total_FP + total_FN + total_TN) if (total_TP + total_FP + total_FN + total_TN) > 0 else 0\n",
    "    specificity = total_TN / (total_TN + total_FP) if (total_TN + total_FP) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        'Landmass Captured': total_landmass_captured,\n",
    "        'Loss': avg_loss,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'IOU': iou,\n",
    "        'Accuracy': accuracy,\n",
    "        'Specificity': specificity\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "# Plotting functions\n",
    "def plot_losses(title, training_loss, validation_loss, training_time=None, y_max=0.3):\n",
    "  # scale losses to fit graph\n",
    "  valid_loss = [min(x,y_max) for x in validation_loss]\n",
    "  train_loss = [min(x, y_max) for x in training_loss]\n",
    "\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(np.arange(1, NUM_EPOCHS+1), train_loss, label=\"train_loss\")\n",
    "  plt.plot(np.arange(1, NUM_EPOCHS+1), valid_loss, label=\"valid_loss\")\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Loss\")\n",
    "  plt.legend(loc=\"upper right\")\n",
    "  if training_time is not None:\n",
    "    plt.text(0, 0.3, f\"Training Time: {training_time}\")\n",
    "\n",
    "  step = y_max / 10\n",
    "  yticks = np.arange(0, y_max+step, step)  # Generate ticks from 0.025 to 0.3 with step 0.025\n",
    "  plt.yticks(yticks)\n",
    "\n",
    "  xticks = np.arange(2, NUM_EPOCHS+2, 2)  # Generate ticks from 0 to num_epochs with step 2\n",
    "  plt.xticks(xticks)\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "def plot_loss_comparison(title, training_losses1, training_losses2, validation_losses1, validation_losses2, compare1 = \"Satellite\", compare2 = \"ImageNet\", y_max=0.3):\n",
    "    # scale losses to fit graph\n",
    "    valid_loss_sat = [min(x, y_max) for x in validation_losses1]\n",
    "    train_loss_sat = [min(x, y_max) for x in training_losses1]\n",
    "    valid_loss_img = [min(x, y_max) for x in validation_losses2]\n",
    "    train_loss_img = [min(x, y_max) for x in training_losses2]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_loss_sat, label=f\"Training loss {compare1}\", color='orange')\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), valid_loss_sat, label=f\"Validation loss {compare1}\", color='orange', linestyle='dashed')\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), train_loss_img, label=f\"Training loss {compare2}\", color='teal')\n",
    "    plt.plot(np.arange(0, NUM_EPOCHS), valid_loss_img, label=f\"Validation loss {compare2}\", color='teal', linestyle='dashed')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    \n",
    "    yticks = np.arange(0.025, 0.325, 0.025)  # Generate ticks from 0.025 to 0.3 with step 0.025\n",
    "    plt.yticks(yticks)\n",
    "    \n",
    "    xticks = np.arange(2, NUM_EPOCHS+2, 2)  # Generate ticks from 0 to num_epochs with step 2\n",
    "    plt.xticks(xticks)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(title: str, metric_dict: dict, metrics: List = ['Precision', 'Recall', 'IOU']):\n",
    "    plt.figure()\n",
    "    for metric in metrics:\n",
    "        plt.plot(np.arange(0, NUM_EPOCHS), [x[metric] for x in metric_dict], label=metric)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    yticks = np.arange(0.0, 1.1, 0.1)\n",
    "    plt.yticks(yticks)\n",
    "\n",
    "    xticks = np.arange(2, NUM_EPOCHS+2, 2)\n",
    "    plt.xticks(xticks)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_comparison_metrics(title, metrics: List[List[dict]], titles: List[str],\n",
    "                             metrics_wanted = ['Precision', 'Recall', 'IOU'], x_label='Metrics', y_label = 'Values', y_lim = 1.1, \n",
    "                             size = (10.0, 6.0), single_metric=False):\n",
    "    plt.figure(figsize=size)\n",
    "    \n",
    "    if single_metric:\n",
    "        for i in range(len(titles)):\n",
    "            plt.bar(titles[i], metrics[i][-1][metrics_wanted[0]])\n",
    "    else:\n",
    "        extracted_metrics = []\n",
    "        for i in range(len(titles)):\n",
    "            metrics_add = []\n",
    "            for k in metrics[i][-1]:\n",
    "                if k in metrics_wanted:\n",
    "                    metrics_add.append(metrics[i][-1][k])\n",
    "            extracted_metrics.append(metrics_add)\n",
    "\n",
    "        print(extracted_metrics)\n",
    "\n",
    "        # Create bar positions\n",
    "        bar_width = 0.8 / len(titles)  # Adjust bar width based on number of titles\n",
    "        r = np.arange(len(metrics_wanted))\n",
    "        \n",
    "        for i in range(len(titles)):\n",
    "            plt.bar([x + i * bar_width for x in r], extracted_metrics[i], width=bar_width, edgecolor='grey', label=titles[i])\n",
    "        plt.xticks([r + bar_width * (len(titles) / 2) for r in range(len(metrics_wanted))], metrics_wanted)\n",
    "\n",
    "        plt.legend()\n",
    "    \n",
    "    # Adding labels\n",
    "    plt.xlabel(x_label, fontweight='bold')\n",
    "    plt.ylabel(y_label, rotation=0, labelpad=len(y_label)*2)\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.ylim(0, y_lim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [14:11<2:07:44, 851.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1/10\n",
      "Train loss: 0.262424, Test loss: 0.2248\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.1012208139551096\n",
      "Precision: 0.8348171414415761\n",
      "Recall: 0.9193180245485095\n",
      "f1_score: 0.8750322782522006\n",
      "IOU: 0.7778287868497347\n",
      "Accuracy: 0.9056962302127051\n",
      "Specificity: 0.8980626501886066\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [28:52<1:55:50, 868.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2/10\n",
      "Train loss: 0.207344, Test loss: 0.2061\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.043541471123337\n",
      "Precision: 0.8681107048557829\n",
      "Recall: 0.9059095242356114\n",
      "f1_score: 0.8866074272699042\n",
      "IOU: 0.7963116056144485\n",
      "Accuracy: 0.9167800261395966\n",
      "Specificity: 0.9228717968563385\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [43:35<1:42:07, 875.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3/10\n",
      "Train loss: 0.188009, Test loss: 0.1757\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.017105393925712\n",
      "Precision: 0.8976381958889571\n",
      "Recall: 0.9129926507686373\n",
      "f1_score: 0.9052503191456095\n",
      "IOU: 0.8269016515621294\n",
      "Accuracy: 0.9313618046209065\n",
      "Specificity: 0.9416557795068095\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [58:21<1:27:56, 879.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4/10\n",
      "Train loss: 0.175390, Test loss: 0.1660\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.0462741526348165\n",
      "Precision: 0.8908690456747949\n",
      "Recall: 0.932093256377144\n",
      "f1_score: 0.9110150318017487\n",
      "IOU: 0.8365726418694674\n",
      "Accuracy: 0.9346056874306142\n",
      "Specificity: 0.9360136402639687\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [1:13:00<1:13:17, 879.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5/10\n",
      "Train loss: 0.166121, Test loss: 0.1666\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.0396905525368247\n",
      "Precision: 0.893227569396052\n",
      "Recall: 0.9286802652925774\n",
      "f1_score: 0.9106089784779241\n",
      "IOU: 0.8358880883795415\n",
      "Accuracy: 0.9345186394002458\n",
      "Specificity: 0.9377904328069954\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [1:27:39<58:37, 879.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6/10\n",
      "Train loss: 0.158174, Test loss: 0.1558\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.0319412429948187\n",
      "Precision: 0.9027115542109762\n",
      "Recall: 0.9315452831511627\n",
      "f1_score: 0.9169017917693791\n",
      "IOU: 0.8465546197027279\n",
      "Accuracy: 0.9393595639983056\n",
      "Specificity: 0.9437386449004084\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [1:42:14<43:53, 877.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7/10\n",
      "Train loss: 0.151238, Test loss: 0.1490\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.0405136434036442\n",
      "Precision: 0.9029405730301928\n",
      "Recall: 0.9395219831519172\n",
      "f1_score: 0.9208681229316723\n",
      "IOU: 0.8533416003180171\n",
      "Accuracy: 0.9420103509078983\n",
      "Specificity: 0.9434048187995614\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [1:56:51<29:14, 877.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 8/10\n",
      "Train loss: 0.146378, Test loss: 0.1438\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.0352720756516731\n",
      "Precision: 0.9080867588823465\n",
      "Recall: 0.9401168643013899\n",
      "f1_score: 0.9238242643453727\n",
      "IOU: 0.8584325345185555\n",
      "Accuracy: 0.9443200750496308\n",
      "Specificity: 0.946675531714635\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [2:11:30<14:37, 877.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9/10\n",
      "Train loss: 0.140711, Test loss: 0.1458\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.029791973452709\n",
      "Precision: 0.9093864521484633\n",
      "Recall: 0.9364788682546468\n",
      "f1_score: 0.9227338377299592\n",
      "IOU: 0.8565513983893756\n",
      "Accuracy: 0.9436751059818781\n",
      "Specificity: 0.9477078388568785\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [2:26:04<00:00, 876.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10/10\n",
      "Train loss: 0.137040, Test loss: 0.1360\n",
      "\n",
      "Validation Metrics:\n",
      "Landmass Captured: 1.02064103893727\n",
      "Precision: 0.9189703475612869\n",
      "Recall: 0.9379388507000025\n",
      "f1_score: 0.9283577166035776\n",
      "IOU: 0.8662944071796755\n",
      "Accuracy: 0.9480102057788823\n",
      "Specificity: 0.9536541389178916\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "model = ResNet_UNet_NoSkip(input_image_size=INPUT_IMAGE_SIZE).to(DEVICE)\n",
    "training_loss, metrics = train(model, trainLoader, testLoader, LOSS, NUM_EPOCHS=NUM_EPOCHS, print_all_epochs=True)\n",
    "valid_loss = [x['Loss'] for x in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet_unet_noskip_224.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Number of parameters\u001b[39;00m\n\u001b[32m      2\u001b[39m res18 = ResNet_UNet()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m NoSkip = \u001b[43mResNet_UNet_NoSkip\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINPUT_IMAGE_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m res18_params = \u001b[38;5;28msum\u001b[39m(p.numel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m res18.parameters())\n\u001b[32m      6\u001b[39m NoSkip_params = \u001b[38;5;28msum\u001b[39m(p.numel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m NoSkip.parameters())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\OneDrive\\Documents\\GitHub\\ml-mangrove\\DroneClassification\\models\\models.py:235\u001b[39m, in \u001b[36mResNet_UNet_NoSkip.__init__\u001b[39m\u001b[34m(self, ResNet, num_classes, input_image_size)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28mself\u001b[39m.encoder = nn.Sequential(\n\u001b[32m    224\u001b[39m     ResNet.conv1,\n\u001b[32m    225\u001b[39m     ResNet.bn1,\n\u001b[32m   (...)\u001b[39m\u001b[32m    231\u001b[39m     ResNet.layer4\n\u001b[32m    232\u001b[39m )\n\u001b[32m    234\u001b[39m dummy_input = torch.randn(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, input_image_size, input_image_size)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[38;5;66;03m# Define feature dimensions\u001b[39;00m\n\u001b[32m    238\u001b[39m feature_dim = x.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gwrye\\anaconda3\\envs\\ml\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "# Number of parameters\n",
    "res18 = ResNet_UNet()\n",
    "NoSkip = ResNet_UNet_NoSkip(input_image_size=INPUT_IMAGE_SIZE)\n",
    "\n",
    "res18_params = sum(p.numel() for p in res18.parameters())\n",
    "NoSkip_params = sum(p.numel() for p in NoSkip.parameters())\n",
    "print(f\"ResNet18 UNet has {res18_params} parameters.\")\n",
    "print(f\"ResNet18 UNet NoSkip has {NoSkip_params} parameters.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
