{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4cedf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MemoryMapDataset import MemmapDataset\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad60195",
   "metadata": {},
   "source": [
    "This notebook shows how to manipulate datasets. The MemmapDataset supports concatenation, shuffling, splitting and saving as separate train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d57c1",
   "metadata": {},
   "source": [
    "## Concatenate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0df3932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\temp1\\images.npy...\n",
      "Array 1: (525, 3, 224, 224), Array 2: (1527, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "Copying Array 2: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (2052, 3, 224, 224), dtype: uint8\n",
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\temp1\\labels.npy...\n",
      "Array 1: (525, 1, 224, 224), Array 2: (1527, 1, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n",
      "Copying Array 2: 100%|██████████| 2/2 [00:00<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (2052, 1, 224, 224), dtype: uint8\n",
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\temp2\\images.npy...\n",
      "Array 1: (60085, 3, 224, 224), Array 2: (2052, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 59/59 [01:24<00:00,  1.43s/it]\n",
      "Copying Array 2: 100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (62137, 3, 224, 224), dtype: uint8\n",
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\temp2\\labels.npy...\n",
      "Array 1: (60085, 1, 224, 224), Array 2: (2052, 1, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 59/59 [00:12<00:00,  4.75it/s]\n",
      "Copying Array 2: 100%|██████████| 3/3 [00:00<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (62137, 1, 224, 224), dtype: uint8\n",
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\downsampled_train\\images.npy...\n",
      "Array 1: (173924, 3, 224, 224), Array 2: (62137, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 170/170 [04:15<00:00,  1.50s/it]\n",
      "Copying Array 2: 100%|██████████| 61/61 [01:27<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (236061, 3, 224, 224), dtype: uint8\n",
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\downsampled_train\\labels.npy...\n",
      "Array 1: (173924, 1, 224, 224), Array 2: (62137, 1, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 170/170 [00:35<00:00,  4.73it/s]\n",
      "Copying Array 2: 100%|██████████| 61/61 [00:15<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (236061, 1, 224, 224), dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "# Concatenate Datasets\n",
    "\n",
    "parent_dir = \"A:\\\\Drone_Datasets\\\\training_data\"\n",
    "\n",
    "one_meter_path = os.path.join(parent_dir, \"1m_train\")\n",
    "half_meter_path = os.path.join(parent_dir, \"0_5m_train\")\n",
    "onetenth_meter_path = os.path.join(parent_dir, \"0_1m_train\")\n",
    "zerosix_meter_path = os.path.join(parent_dir, \"0_06m_train\")\n",
    "original_path = os.path.join(parent_dir, \"original_train\")\n",
    "concatenated_path = os.path.join(parent_dir, \"multiresolution_train\")\n",
    "\n",
    "one_meter_dataset = MemmapDataset(np.load(os.path.join(one_meter_path, \"images.npy\"), mmap_mode='r'),\n",
    "                                  np.load(os.path.join(one_meter_path, \"labels.npy\"), mmap_mode='r'))\n",
    "half_meter_dataset = MemmapDataset(np.load(os.path.join(half_meter_path, \"images.npy\"), mmap_mode='r'),\n",
    "                                   np.load(os.path.join(half_meter_path, \"labels.npy\"), mmap_mode='r'))\n",
    "onetenth_meter_dataset = MemmapDataset(np.load(os.path.join(onetenth_meter_path, \"images.npy\"), mmap_mode='r'),\n",
    "                                       np.load(os.path.join(onetenth_meter_path, \"labels.npy\"), mmap_mode='r'))\n",
    "zerosix_meter_dataset = MemmapDataset(np.load(os.path.join(zerosix_meter_path, \"images.npy\"), mmap_mode='r'),\n",
    "                                      np.load(os.path.join(zerosix_meter_path, \"labels.npy\"), mmap_mode='r'))\n",
    "original_dataset = MemmapDataset(np.load(os.path.join(original_path, \"images.npy\"), mmap_mode='r'),\n",
    "                                  np.load(os.path.join(original_path, \"labels.npy\"), mmap_mode='r'))\n",
    "\n",
    "temp_dataset1 = one_meter_dataset.concat(half_meter_dataset, os.path.join(parent_dir, \"temp1\"))\n",
    "del one_meter_dataset, half_meter_dataset\n",
    "temp_dataset2 = onetenth_meter_dataset.concat(temp_dataset1, os.path.join(parent_dir, \"temp2\"))\n",
    "del onetenth_meter_dataset, temp_dataset1\n",
    "temp_dataset3 = zerosix_meter_dataset.concat(temp_dataset2, os.path.join(parent_dir, \"downsampled_train\"))\n",
    "del zerosix_meter_dataset, temp_dataset2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acc6e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\multiresolution_train\\images.npy...\n",
      "Array 1: (612071, 3, 224, 224), Array 2: (236061, 3, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 598/598 [15:02<00:00,  1.51s/it]\n",
      "Copying Array 2: 100%|██████████| 231/231 [05:44<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (848132, 3, 224, 224), dtype: uint8\n",
      "\n",
      "Concatenating to A:\\Drone_Datasets\\training_data\\multiresolution_train\\labels.npy...\n",
      "Array 1: (612071, 1, 224, 224), Array 2: (236061, 1, 224, 224)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Array 1: 100%|██████████| 598/598 [02:31<00:00,  3.94it/s]\n",
      "Copying Array 2: 100%|██████████| 231/231 [01:11<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting output array shape: (848132, 1, 224, 224), dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "final_dataset = original_dataset.concat(temp_dataset3, concatenated_path)\n",
    "del original_dataset, temp_dataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c991f6eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Downloads\\\\Vaihingen_Potsdam_09cm\\\\Potsdam\\\\Chunks\\\\224dataset_images.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m potsdam_path = os.path.join(parent_dir, \u001b[33m\"\u001b[39m\u001b[33mPotsdam\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mChunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m vaihingen_path = os.path.join(parent_dir, \u001b[33m\"\u001b[39m\u001b[33mVaihingen\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mChunks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m potsdam_dataset = MemmapDataset(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpotsdam_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m224dataset_images.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[32m      9\u001b[39m                                 np.load(os.path.join(potsdam_path, \u001b[33m\"\u001b[39m\u001b[33m224dataset_labels.npy\u001b[39m\u001b[33m\"\u001b[39m), mmap_mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     10\u001b[39m vaihingen_dataset = MemmapDataset(np.load(os.path.join(vaihingen_path, \u001b[33m\"\u001b[39m\u001b[33m224dataset_images.npy\u001b[39m\u001b[33m\"\u001b[39m), mmap_mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     11\u001b[39m                                  np.load(os.path.join(vaihingen_path, \u001b[33m\"\u001b[39m\u001b[33m224dataset_labels.npy\u001b[39m\u001b[33m\"\u001b[39m), mmap_mode=\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     13\u001b[39m final_dataset = potsdam_dataset.concat(vaihingen_dataset, os.path.join(parent_dir, \u001b[33m\"\u001b[39m\u001b[33mcombined_dataset\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32ma:\\anaconda3\\envs\\machine\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Downloads\\\\Vaihingen_Potsdam_09cm\\\\Potsdam\\\\Chunks\\\\224dataset_images.npy'"
     ]
    }
   ],
   "source": [
    "# Concatenate Datasets\n",
    "\n",
    "parent_dir = \"C:\\\\Downloads\\\\Vaihingen_Potsdam_09cm\"\n",
    "\n",
    "potsdam_path = os.path.join(parent_dir, \"Potsdam\\\\Chunks\")\n",
    "vaihingen_path = os.path.join(parent_dir, \"Vaihingen\\\\Chunks\")\n",
    "\n",
    "potsdam_dataset = MemmapDataset(np.load(os.path.join(potsdam_path, \"224dataset_images.npy\"), mmap_mode='r'),\n",
    "                                np.load(os.path.join(potsdam_path, \"224dataset_labels.npy\"), mmap_mode='r'))\n",
    "vaihingen_dataset = MemmapDataset(np.load(os.path.join(vaihingen_path, \"224dataset_images.npy\"), mmap_mode='r'),\n",
    "                                 np.load(os.path.join(vaihingen_path, \"224dataset_labels.npy\"), mmap_mode='r'))\n",
    "\n",
    "final_dataset = potsdam_dataset.concat(vaihingen_dataset, os.path.join(parent_dir, \"combined_dataset\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
