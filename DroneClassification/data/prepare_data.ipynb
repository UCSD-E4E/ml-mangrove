{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiff_processing_utils import tile_tiff_pair, rasterize_shapefile\n",
    "from MemoryMapDataset import MemmapDataset\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing pipeline assumes that the data in the Chunks folder is in the following format:\n",
    "- Each chunk is in it's own folder and named 'Chunk x' or 'Chunk x x-x'\n",
    "- The RGB tif should be named 'Chunkx.tif' or 'Chunkx_x-x.tif'\n",
    "- label shape file and corresponding label files should be in a folder called 'labels' inside of the matching 'Chunk x' / 'Chunk x x-x' folder, the names of the files do not need to be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\gwrye\\\\OneDrive\\\\Desktop\\\\Original_Drone_Dataset\"\n",
    "\n",
    "TILE_SIZE = 224\n",
    "\n",
    "combined_images_file = os.path.join(base_path, f'{TILE_SIZE}dataset_images.npy')\n",
    "combined_labels_file = os.path.join(base_path, f'{TILE_SIZE}dataset_labels.npy')\n",
    "\n",
    "# RAM thresholds\n",
    "TOTAL_RAM_MB = psutil.virtual_memory().total / (1024 ** 2)\n",
    "SAFE_RAM_USAGE_MB = TOTAL_RAM_MB - 16 * 1024  # 16GB below total RAM\n",
    "CHUNK_BUFFER_SIZE = 10  # Number of chunks to keep in memory at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all label shape files to tif\n",
    "for entry in os.listdir(base_path):\n",
    "    if 'Chunk' in entry:\n",
    "        chunk_path = os.path.join(base_path, entry)\n",
    "        rasterized_shape = rasterize_shapefile(chunk_path)\n",
    "print('\\nDone rasterizing shapefiles')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to monitor memory usage\n",
    "def print_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    print(f\"Memory Usage: {mem_info.rss / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 ** 2)  # Return memory usage in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert all tif pairs into tiled datasets\n",
    "\n",
    "NOTE: This will take a lot of time, memory, and storage space.\n",
    "You should have at least 32GB of RAM and triple the chunk folder size of storage. If you don't have enough RAM,\n",
    "you can run this script in smaller chunks by lowering the CHUNK_BUFFER_SIZE variable.\n",
    "\"\"\"\n",
    "\n",
    "# Function to append data to memory-mapped file\n",
    "def append_to_memmap(file_path, data, dtype):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Creating new memmap file at {file_path}\")\n",
    "        new_memmap = np.lib.format.open_memmap(file_path, mode='w+', dtype=dtype, shape=data.shape)\n",
    "        new_memmap[:] = data\n",
    "    else:\n",
    "        existing_shape = np.load(file_path).shape\n",
    "        new_shape = (existing_shape[0] + data.shape[0],) + existing_shape[1:]\n",
    "\n",
    "        temp_file_path = file_path + '.tmp'\n",
    "        new_memmap = np.lib.format.open_memmap(temp_file_path, mode='w+', dtype=dtype, shape=new_shape)\n",
    "\n",
    "        \n",
    "        old_memmap = np.lib.format.open_memmap(file_path, mode='r')\n",
    "        new_memmap[:existing_shape[0]] = old_memmap[:]\n",
    "        new_memmap[existing_shape[0]:] = data\n",
    "\n",
    "        new_memmap.flush()\n",
    "        del new_memmap\n",
    "        del old_memmap\n",
    "        gc.collect()\n",
    "        \n",
    "        # Replace the original file with the temporary file\n",
    "        os.replace(temp_file_path, file_path)\n",
    "\n",
    "# Buffer for storing data before appending to memmap\n",
    "image_buffer = []\n",
    "label_buffer = []\n",
    "\n",
    "num_chunks = len([entry for entry in os.listdir(base_path) if 'Chunk' in entry])\n",
    "print(f\"Processing {num_chunks} chunk directories\")\n",
    "\n",
    "# Iterate over each chunk directory and process TIFF pairs\n",
    "current_chunk = 0\n",
    "for entry in os.listdir(base_path):\n",
    "    if 'Chunk' in entry:\n",
    "        current_chunk += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        if current_chunk < 42:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        print(f\"\\nChunk {current_chunk}/{num_chunks}\")\n",
    "        chunk_path = os.path.join(base_path, entry)\n",
    "        \n",
    "        # Generate tiled images and labels\n",
    "        images, labels = tile_tiff_pair(chunk_path, image_size=TILE_SIZE)\n",
    "        if images.size == 0:\n",
    "            print(f\"No valid tiles found at {entry}\")\n",
    "            continue\n",
    "        \n",
    "        # Add to buffer\n",
    "        image_buffer.append(images)\n",
    "        label_buffer.append(labels)\n",
    "\n",
    "        # Check memory usage and append to memmap if within threshold\n",
    "        current_memory_usage = get_memory_usage()\n",
    "        if current_memory_usage > SAFE_RAM_USAGE_MB or current_chunk % CHUNK_BUFFER_SIZE == 0:\n",
    "            if current_memory_usage > SAFE_RAM_USAGE_MB:\n",
    "                print(f\"Memory usage {current_memory_usage:.2f} MB exceeds {SAFE_RAM_USAGE_MB} threshold. Appending to memmap.\")\n",
    "            else:\n",
    "                print(\"Appending to memmap...\")\n",
    "\n",
    "            images_to_append = np.concatenate(image_buffer, axis=0)\n",
    "            append_to_memmap(combined_images_file, images_to_append, np.uint8)\n",
    "            image_buffer = []\n",
    "            del images_to_append\n",
    "\n",
    "            labels_to_append = np.concatenate(label_buffer, axis=0)\n",
    "            append_to_memmap(combined_labels_file, labels_to_append, np.uint8)\n",
    "            label_buffer = []\n",
    "            del labels_to_append\n",
    "            gc.collect()\n",
    "\n",
    "# Final append if buffer is not empty\n",
    "if image_buffer:\n",
    "    print(\"Appending remaining buffered data to memmap.\")\n",
    "\n",
    "    images_to_append = np.concatenate(image_buffer, axis=0)\n",
    "    append_to_memmap(combined_images_file, images_to_append, np.uint8)\n",
    "    image_buffer = []\n",
    "    del images_to_append\n",
    "\n",
    "    labels_to_append = np.concatenate(label_buffer, axis=0)\n",
    "    append_to_memmap(combined_labels_file, labels_to_append, np.uint8)\n",
    "    label_buffer = []\n",
    "    del labels_to_append\n",
    "\n",
    "print('\\nDone tiling tif pairs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data one entry at a time using Fisher-Yates shuffle\n",
    "# This is necessary because the data is too large to load into memory all at once\n",
    "def shuffle_data(images_path, labels_path):\n",
    "    images = np.load(images_path, mmap_mode='r+')\n",
    "    labels = np.load(labels_path, mmap_mode='r+')\n",
    "\n",
    "    dataset_size = images.shape[0]\n",
    "\n",
    "    for i in range(dataset_size-1, 0, -1):\n",
    "        print(f\"Percent Shuffled: {100*(dataset_size-i)/dataset_size:.2f}%\", end='\\r')\n",
    "        j = np.random.randint(0, i+1)\n",
    "        images[i], images[j] = images[j], images[i]\n",
    "        labels[i], labels[j] = labels[j], labels[i]\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            del images\n",
    "            del labels\n",
    "            gc.collect()\n",
    "            \n",
    "            images = np.load(images_path, mmap_mode='r+')\n",
    "            labels = np.load(labels_path, mmap_mode='r+')\n",
    "\n",
    "\n",
    "\n",
    "shuffle_data(combined_images_file, combined_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "\n",
    "images = np.load(combined_images_file, mmap_mode='r+')\n",
    "labels = np.load(combined_labels_file, mmap_mode='r+')\n",
    "\n",
    "dataset = MemmapDataset(images, labels)\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Dataset image shape: {dataset.images[0].shape}\")\n",
    "print(f\"Dataset label shape: {dataset.labels[0].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
