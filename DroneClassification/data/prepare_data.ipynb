{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import tile_dataset, rasterize_shapefiles, resample\n",
    "from MemoryMapDataset import MemmapDataset\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing pipeline assumes that the data in the Path folder is in the following format:\n",
    "- Each chunk is in it's own folder and named 'Chunk x' or 'Chunk x x-x'\n",
    "- The RGB tif should be named 'Chunkx.tif' or 'Chunkx_x-x.tif'\n",
    "- label shape file and corresponding label files should be in a folder called 'labels' inside of the matching 'Chunk x' / 'Chunk x x-x' folder, the names of the files do not need to be formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 chunks can be buffered in RAM at a time based on 48GB available RAM.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "BASE_PATH = \"A:\\\\Desktop\\\\Drone_Data\"\n",
    "DATA_PATH = os.path.join(BASE_PATH, \"original_data\")\n",
    "TILE_SIZE = 224\n",
    "\n",
    "COMBINED_IMAGES_FILE = os.path.join(DATA_PATH, f'{TILE_SIZE}dataset_images.npy')\n",
    "COMBINED_LABELS_FILE = os.path.join(DATA_PATH, f'{TILE_SIZE}dataset_labels.npy')\n",
    "\n",
    "# Find how many chunks can be buffered at a time based on RAM threshold\n",
    "average_chunk_size = 2 # Average chunk size in GB.\n",
    "available_ram = psutil.virtual_memory().available / (1024 ** 2)\n",
    "safe_ram_usage = available_ram - (8 + average_chunk_size) * 1024  # 8GB + chunk size below total RAM\n",
    "CHUNK_BUFFER_SIZE = int(safe_ram_usage // (average_chunk_size * 1024))\n",
    "\n",
    "if CHUNK_BUFFER_SIZE <= 0:\n",
    "    raise ValueError(\"Insufficient RAM to process chunks. Please increase available RAM or reduce average chunk size and proceed with caution.\")\n",
    "\n",
    "print(CHUNK_BUFFER_SIZE, f\"chunks can be buffered in RAM at a time based on {int(available_ram // 1024)}GB available RAM.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If desired, resample the TIFF files to a lower resolution\n",
    "\n",
    "resample_tiffs = False  # Set to True if you want to resample TIFF files\n",
    "target_resolution = 0.06  # in meters\n",
    "resample_output_path = os.path.join(BASE_PATH, str(target_resolution).replace('.', '_') + \"m\")\n",
    "\n",
    "if resample_tiffs:\n",
    "    if os.path.exists(resample_output_path):\n",
    "        print(\"Resampled data already exists at\", resample_output_path,\". Setting PATH to resampled directory.\")\n",
    "    else:\n",
    "        resample(DATA_PATH, resample_output_path, target_resolution)\n",
    "    \n",
    "    DATA_PATH = resample_output_path  # Update PATH to the resampled directory\n",
    "    COMBINED_IMAGES_FILE = os.path.join(DATA_PATH, f'{TILE_SIZE}dataset_images.npy')\n",
    "    COMBINED_LABELS_FILE = os.path.join(DATA_PATH, f'{TILE_SIZE}dataset_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all label shape files to tif\n",
    "rasterize_shapefiles(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all tif pairs into tiled datasets\n",
    "\n",
    "\"\"\"\n",
    "NOTE: This will take a lot of time, memory, and storage space.\n",
    "You should have at least 32GB of RAM and triple the chunk folder size of storage. If you don't have enough RAM,\n",
    "you can run this script in smaller chunks by lowering the CHUNK_BUFFER_SIZE variable.\n",
    "\"\"\"\n",
    "\n",
    "tile_dataset(DATA_PATH, COMBINED_IMAGES_FILE, COMBINED_LABELS_FILE, chunk_buffer_size=CHUNK_BUFFER_SIZE, image_size=TILE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Shuffled: 100.00%\r"
     ]
    }
   ],
   "source": [
    "# Shuffle data one entry at a time using Fisher-Yates shuffle\n",
    "def shuffle_data(images_path, labels_path):\n",
    "    images = np.load(images_path, mmap_mode='r+')\n",
    "    labels = np.load(labels_path, mmap_mode='r+')\n",
    "\n",
    "    dataset_size = images.shape[0]\n",
    "\n",
    "    for i in range(dataset_size-1, 0, -1):\n",
    "        print(f\"Percent Shuffled: {100*(dataset_size-i)/dataset_size:.2f}%\", end='\\r')\n",
    "        j = np.random.randint(0, i+1)\n",
    "        images[i], images[j] = images[j], images[i]\n",
    "        labels[i], labels[j] = labels[j], labels[i]\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            del images\n",
    "            del labels\n",
    "            gc.collect()\n",
    "            \n",
    "            images = np.load(images_path, mmap_mode='r+')\n",
    "            labels = np.load(labels_path, mmap_mode='r+')\n",
    "\n",
    "\n",
    "\n",
    "shuffle_data(COMBINED_IMAGES_FILE, COMBINED_LABELS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 193249\n",
      "Dataset image shape: (3, 224, 224)\n",
      "Dataset label shape: (1, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "\n",
    "images = np.load(COMBINED_IMAGES_FILE, mmap_mode='r+')\n",
    "labels = np.load(COMBINED_LABELS_FILE, mmap_mode='r+')\n",
    "\n",
    "dataset = MemmapDataset(images, labels)\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Dataset image shape: {dataset.images[0].shape}\")\n",
    "print(f\"Dataset label shape: {dataset.labels[0].shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
