{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Gated Ensemble: Landcover + Mangrove Models on 0.5m Data\n\nRun both models on our private 0.5m mangrove dataset and combine predictions\nvia a gated ensemble.\n\n**Landcover Model**: SegFormer trained on Landcover.ai v1\n- 5 output classes: Background, Building, Woodland, Water, Road\n\n**Mangrove Model**: SegFormer trained on 0.5m mangrove data\n- Binary output: Mangrove / Not Mangrove\n\n**Gated Ensemble Strategy**:\nThe landcover model cannot distinguish between woodland and mangrove â€” it labels\nmost mangrove pixels as \"woodland\". We use the mangrove model as a gate:\nwherever it predicts **mangrove**, we override the landcover prediction with a\ndedicated **mangrove** class. This produces a 6-class output:\n\n| Class | Label |\n|-------|-------|\n| 0 | Background |\n| 1 | Building |\n| 2 | Woodland |\n| 3 | Water |\n| 4 | Road |\n| 5 | **Mangrove** (gated) |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport json\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nfrom pathlib import Path\nfrom tqdm import tqdm\n\n# ============================================================\n# CONFIGURATION\n# ============================================================\n\n# Paths\nDATA_ROOT = Path('../data/0_5m')\nWEIGHTS_DIR = Path('../weights')\nPLOTS_DIR = Path('../plots/landcover_05m_inference')\n\n# Data files\nIMAGES_FILE = DATA_ROOT / '512dataset_images.npy'\nLABELS_FILE = DATA_ROOT / '512dataset_labels.npy'\n\n# --- Landcover model (5 classes) ---\nMODEL_NAME = 'segformer'\nLANDCOVER_WEIGHTS = WEIGHTS_DIR / 'human_segformer.pth'\nLANDCOVER_NUM_CLASSES = 5\n\n# --- Mangrove model (binary) ---\nMANGROVE_WEIGHTS = WEIGHTS_DIR / 'mangrove_segformer.pth'\nMANGROVE_NUM_CLASSES = 1  # sigmoid output\n\nBATCH_SIZE = 16\nNUM_WORKERS = 0\nIGNORE_INDEX = 255\nMANGROVE_THRESHOLD = 0.5\n\n# Landcover class definitions (model output, 0-4)\nLANDCOVER_NAMES = ['background', 'building', 'woodland', 'water', 'road']\nLANDCOVER_COLORS = {\n    0: [0.8, 0.8, 0.8],  # Background - gray\n    1: [1.0, 0.0, 0.0],  # Building - red\n    2: [0.0, 0.5, 0.0],  # Woodland - dark green\n    3: [0.0, 0.0, 1.0],  # Water - blue\n    4: [1.0, 1.0, 0.0],  # Road - yellow\n}\n\n# Ensemble output: 6 classes (landcover 0-4 + mangrove gate 5)\nENSEMBLE_NAMES = ['background', 'building', 'woodland', 'water', 'road', 'mangrove']\nNUM_ENSEMBLE_CLASSES = 6\nENSEMBLE_COLORS = {\n    0: [0.8, 0.8, 0.8],  # Background - gray\n    1: [1.0, 0.0, 0.0],  # Building - red\n    2: [0.0, 0.5, 0.0],  # Woodland - dark green\n    3: [0.0, 0.0, 1.0],  # Water - blue\n    4: [1.0, 1.0, 0.0],  # Road - yellow\n    5: [0.0, 0.9, 0.4],  # Mangrove - bright green\n}\n\n# Mangrove GT legend\nMANGROVE_NAMES = ['not_mangrove', 'mangrove']\nMANGROVE_COLORS = {\n    0: [0.8, 0.8, 0.8],\n    1: [0.0, 0.7, 0.0],\n}\n\nPLOTS_DIR.mkdir(parents=True, exist_ok=True)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Device: {device}\")\nprint(f\"Landcover weights: {LANDCOVER_WEIGHTS}\")\nprint(f\"Mangrove weights:  {MANGROVE_WEIGHTS}\")\nprint(f\"Target data: {DATA_ROOT}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Load Models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "sys.path.insert(0, '../../')\n\nfrom models import SegFormer\n\nprint(\"=== Loading Landcover Model (5-class) ===\")\nlandcover_model = SegFormer(num_classes=LANDCOVER_NUM_CLASSES)\nstate_dict = torch.load(LANDCOVER_WEIGHTS, map_location=device)\nlandcover_model.load_state_dict(state_dict)\nlandcover_model = landcover_model.to(device)\nlandcover_model.eval()\nprint(f\"Loaded: {LANDCOVER_WEIGHTS}\")\n\nprint()\n\nprint(\"=== Loading Mangrove Model (binary) ===\")\nmangrove_model = SegFormer(num_classes=MANGROVE_NUM_CLASSES)\nstate_dict = torch.load(MANGROVE_WEIGHTS, map_location=device)\nmangrove_model.load_state_dict(state_dict)\nmangrove_model = mangrove_model.to(device)\nmangrove_model.eval()\nprint(f\"Loaded: {MANGROVE_WEIGHTS}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Mangrove Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Mangrove Dataset ===\n",
      "\n",
      "Loaded 573 samples\n",
      "\n",
      "Total samples: 573\n",
      "Batches: 36\n"
     ]
    }
   ],
   "source": [
    "class MangroveDataset(Dataset):\n",
    "    \"\"\"Load 0.5m mangrove .npy data for inference.\"\"\"\n",
    "    \n",
    "    MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    STD = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    \n",
    "    def __init__(self, images_path, labels_path, indices=None):\n",
    "        self.images = np.load(images_path, mmap_mode='r')\n",
    "        self.labels = np.load(labels_path, mmap_mode='r')\n",
    "        self.indices = indices if indices is not None else np.arange(len(self.images))\n",
    "        print(f\"Loaded {len(self.indices)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        \n",
    "        image = self.images[real_idx].copy()\n",
    "        label = self.labels[real_idx].copy()\n",
    "        \n",
    "        image = torch.from_numpy(image).float()\n",
    "        if image.max() > 1.5:\n",
    "            image = image / 255.0\n",
    "        image = (image - self.MEAN) / self.STD\n",
    "        \n",
    "        label = torch.from_numpy(label).long()\n",
    "        if label.dim() == 3:\n",
    "            label = label.squeeze(0)\n",
    "        \n",
    "        return image, label, real_idx\n",
    "\n",
    "\n",
    "print(\"=== Loading Mangrove Dataset ===\")\n",
    "print()\n",
    "\n",
    "# Load all samples\n",
    "dataset = MangroveDataset(IMAGES_FILE, LABELS_FILE)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal samples: {len(dataset):,}\")\n",
    "print(f\"Batches: {len(loader):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Run Gated Ensemble Inference"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=== Running Gated Ensemble Inference ===\")\nprint()\n\nall_landcover_preds = []\nall_mangrove_preds = []\nall_targets = []\n\nwith torch.no_grad():\n    for images, masks, _ in tqdm(loader, desc=\"Inference\"):\n        images = images.to(device)\n\n        # Landcover model: 5-class argmax\n        lc_out = landcover_model(images)\n        lc_preds = torch.argmax(lc_out, dim=1)\n\n        # Mangrove model: binary sigmoid\n        mg_out = mangrove_model(images)\n        mg_preds = (torch.sigmoid(mg_out) > MANGROVE_THRESHOLD).squeeze(1).long()\n\n        all_landcover_preds.append(lc_preds.cpu().numpy())\n        all_mangrove_preds.append(mg_preds.cpu().numpy())\n        all_targets.append(masks.numpy())\n\nall_landcover_preds = np.concatenate(all_landcover_preds, axis=0)\nall_mangrove_preds = np.concatenate(all_mangrove_preds, axis=0)\nall_targets = np.concatenate(all_targets, axis=0)\n\n# --- Apply gated ensemble ---\n# Start with landcover predictions (classes 0-4)\n# Where mangrove model says mangrove -> override with class 5\nall_ensemble_preds = all_landcover_preds.copy()\nmangrove_gate = all_mangrove_preds == 1\nall_ensemble_preds[mangrove_gate] = 5  # mangrove class\n\ntorch.cuda.empty_cache()\n\nprint(f\"\\nLandcover preds shape: {all_landcover_preds.shape}\")\nprint(f\"Mangrove preds shape:  {all_mangrove_preds.shape}\")\nprint(f\"Ensemble preds shape:  {all_ensemble_preds.shape}\")\nprint(f\"Ensemble classes present: {np.unique(all_ensemble_preds).tolist()}\")\nprint(f\"Pixels gated to mangrove: {mangrove_gate.sum():,} ({mangrove_gate.mean()*100:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Ensemble Class Distribution Analysis\n\nWhat does the gated ensemble predict across the dataset?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=== Ensemble Prediction Distribution ===\")\nprint()\n\npreds_flat = all_ensemble_preds.flatten()\ntargets_flat = all_targets.flatten()\n\ntotal_pixels = len(preds_flat)\nprint(f\"Total pixels: {total_pixels:,}\")\nprint()\nprint(\"Ensemble prediction distribution:\")\nprint(f\"{'Class':<12} {'Count':>12} {'Percentage':>10}\")\nprint(\"-\" * 36)\n\npred_counts = {}\nfor c in range(NUM_ENSEMBLE_CLASSES):\n    count = (preds_flat == c).sum()\n    pct = count / total_pixels * 100\n    pred_counts[c] = count\n    print(f\"{ENSEMBLE_NAMES[c]:<12} {count:>12,} {pct:>9.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Breakdown: what does the ensemble predict for mangrove vs non-mangrove pixels?\nprint(\"=== Ensemble Predictions Conditioned on Ground Truth ===\")\nprint()\n\nfor gt_class, gt_name in enumerate(MANGROVE_NAMES):\n    mask = targets_flat == gt_class\n    if mask.sum() == 0:\n        continue\n\n    gt_preds = preds_flat[mask]\n    gt_total = len(gt_preds)\n\n    print(f\"Where ground truth = {gt_name} ({gt_total:,} pixels):\")\n    for c in range(NUM_ENSEMBLE_CLASSES):\n        count = (gt_preds == c).sum()\n        pct = count / gt_total * 100\n        bar = '#' * int(pct / 2)\n        print(f\"  -> {ENSEMBLE_NAMES[c]:<12}: {pct:>5.1f}%  {bar}\")\n    print()\n\n# Also show ignore pixels\nignore_mask = targets_flat == IGNORE_INDEX\nif ignore_mask.sum() > 0:\n    ignore_preds = preds_flat[ignore_mask]\n    ignore_total = len(ignore_preds)\n    print(f\"Where ground truth = ignore/255 ({ignore_total:,} pixels):\")\n    for c in range(NUM_ENSEMBLE_CLASSES):\n        count = (ignore_preds == c).sum()\n        pct = count / ignore_total * 100\n        print(f\"  -> {ENSEMBLE_NAMES[c]:<12}: {pct:>5.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=== Plotting Ensemble Distribution ===\")\nprint()\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 5))\nfig.suptitle('Gated Ensemble Predictions on 0.5m Mangrove Data', fontsize=14, fontweight='bold')\n\ncolors = [ENSEMBLE_COLORS[i] for i in range(NUM_ENSEMBLE_CLASSES)]\n\n# 1. Overall\ncounts = [pred_counts[c] for c in range(NUM_ENSEMBLE_CLASSES)]\naxes[0].bar(ENSEMBLE_NAMES, counts, color=colors, edgecolor='black')\naxes[0].set_title('Overall Ensemble Distribution')\naxes[0].set_ylabel('Pixel Count')\naxes[0].tick_params(axis='x', rotation=45)\n\n# 2. Predictions where GT = mangrove\nmangrove_mask = targets_flat == 1\nif mangrove_mask.sum() > 0:\n    mangrove_preds_cond = preds_flat[mangrove_mask]\n    m_pcts = [(mangrove_preds_cond == c).sum() / len(mangrove_preds_cond) * 100 for c in range(NUM_ENSEMBLE_CLASSES)]\n    bars = axes[1].bar(ENSEMBLE_NAMES, m_pcts, color=colors, edgecolor='black')\n    for bar, pct in zip(bars, m_pcts):\n        if pct > 1:\n            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n                        f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n    axes[1].set_title('Ensemble on MANGROVE pixels')\n    axes[1].set_ylabel('Percentage (%)')\n    axes[1].tick_params(axis='x', rotation=45)\n\n# 3. Predictions where GT = not_mangrove\nnonmangrove_mask = targets_flat == 0\nif nonmangrove_mask.sum() > 0:\n    nm_preds = preds_flat[nonmangrove_mask]\n    nm_pcts = [(nm_preds == c).sum() / len(nm_preds) * 100 for c in range(NUM_ENSEMBLE_CLASSES)]\n    bars = axes[2].bar(ENSEMBLE_NAMES, nm_pcts, color=colors, edgecolor='black')\n    for bar, pct in zip(bars, nm_pcts):\n        if pct > 1:\n            axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n                        f'{pct:.1f}%', ha='center', va='bottom', fontsize=9)\n    axes[2].set_title('Ensemble on NOT MANGROVE pixels')\n    axes[2].set_ylabel('Percentage (%)')\n    axes[2].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.savefig(PLOTS_DIR / 'ensemble_distribution.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(f\"Saved: {PLOTS_DIR / 'ensemble_distribution.png'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization functions defined\n"
     ]
    }
   ],
   "source": [
    "def denormalize(img):\n",
    "    \"\"\"Reverse ImageNet normalization.\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(-1, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(-1, 1, 1)\n",
    "    return torch.clamp(img * std + mean, 0, 1)\n",
    "\n",
    "\n",
    "def mask_to_rgb(mask, class_colors, ignore_index=None):\n",
    "    \"\"\"Convert class mask to RGB.\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgb = np.zeros((h, w, 3))\n",
    "    for class_id, color in class_colors.items():\n",
    "        rgb[mask == class_id] = color\n",
    "    if ignore_index is not None:\n",
    "        rgb[mask == ignore_index] = [1.0, 1.0, 1.0]  # White for ignore\n",
    "    return rgb\n",
    "\n",
    "\n",
    "print(\"Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=== Grid Visualization ===\")\nprint()\n\nn_samples = 8\nnp.random.seed(67)\nsample_indices = np.random.choice(len(dataset), n_samples, replace=False)\n\nfig, axes = plt.subplots(n_samples, 5, figsize=(25, 5 * n_samples))\nfig.suptitle('Gated Ensemble: Landcover + Mangrove on 0.5m Data', fontsize=16, fontweight='bold')\n\ncol_titles = ['Image', 'Ground Truth', 'Landcover Pred', 'Mangrove Pred', 'Ensemble']\n\ntorch.cuda.empty_cache()\n\nwith torch.no_grad():\n    for row, idx in enumerate(sample_indices):\n        img, mask, real_idx = dataset[idx]\n        img_dev = img.unsqueeze(0).to(device)\n\n        lc_pred = torch.argmax(landcover_model(img_dev), dim=1).squeeze().cpu().numpy()\n        mg_pred = (torch.sigmoid(mangrove_model(img_dev)) > MANGROVE_THRESHOLD).squeeze().cpu().numpy()\n\n        # Ensemble: landcover base, mangrove gate overrides to class 5\n        ens_pred = lc_pred.copy()\n        ens_pred[mg_pred == 1] = 5\n\n        img_np = denormalize(img).numpy().transpose(1, 2, 0)\n        mask_np = mask.numpy()\n\n        # Image\n        axes[row, 0].imshow(img_np)\n        axes[row, 0].set_ylabel(f'idx={real_idx}', fontsize=10)\n        axes[row, 0].axis('off')\n\n        # Ground truth (binary)\n        axes[row, 1].imshow(mask_to_rgb(mask_np, MANGROVE_COLORS, IGNORE_INDEX))\n        axes[row, 1].axis('off')\n\n        # Landcover prediction (5-class)\n        axes[row, 2].imshow(mask_to_rgb(lc_pred, LANDCOVER_COLORS))\n        axes[row, 2].axis('off')\n\n        # Mangrove prediction (binary)\n        mg_vis = {0: [0.8, 0.8, 0.8], 1: [0.0, 0.9, 0.4]}\n        axes[row, 3].imshow(mask_to_rgb(mg_pred.astype(int), mg_vis))\n        axes[row, 3].axis('off')\n\n        # Ensemble (6-class)\n        axes[row, 4].imshow(mask_to_rgb(ens_pred, ENSEMBLE_COLORS))\n        axes[row, 4].axis('off')\n\n        if row == 0:\n            for col, title in enumerate(col_titles):\n                axes[row, col].set_title(title, fontsize=12)\n\nplt.tight_layout()\nplt.savefig(PLOTS_DIR / 'ensemble_grid.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint(f\"Saved: {PLOTS_DIR / 'ensemble_grid.png'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Per-Sample Inspection\n",
    "\n",
    "Pick specific indices to examine in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def inspect_sample(landcover_model, mangrove_model, dataset, idx):\n    \"\"\"Detailed inspection of a single sample with gated ensemble.\"\"\"\n    torch.cuda.empty_cache()\n\n    img, mask, real_idx = dataset[idx]\n\n    with torch.no_grad():\n        img_dev = img.unsqueeze(0).to(device)\n        lc_pred = torch.argmax(landcover_model(img_dev), dim=1).squeeze().cpu().numpy()\n        mg_pred = (torch.sigmoid(mangrove_model(img_dev)) > MANGROVE_THRESHOLD).squeeze().cpu().numpy()\n\n    ens_pred = lc_pred.copy()\n    ens_pred[mg_pred == 1] = 5\n\n    img_np = denormalize(img).numpy().transpose(1, 2, 0)\n    mask_np = mask.numpy()\n\n    valid = mask_np != IGNORE_INDEX\n    total_valid = valid.sum()\n\n    print(f\"Sample {real_idx}:\")\n    print(f\"  GT mangrove: {(mask_np == 1).sum() / total_valid * 100:.1f}%\")\n    print(f\"  Ensemble predictions:\")\n    for c in range(NUM_ENSEMBLE_CLASSES):\n        pct = (ens_pred[valid] == c).sum() / total_valid * 100\n        print(f\"    {ENSEMBLE_NAMES[c]:<12}: {pct:>5.1f}%\")\n\n    fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n    fig.suptitle(f'Sample {real_idx}', fontsize=14)\n\n    axes[0].imshow(img_np)\n    axes[0].set_title('Image')\n    axes[0].axis('off')\n\n    axes[1].imshow(mask_to_rgb(mask_np, MANGROVE_COLORS, IGNORE_INDEX))\n    axes[1].set_title('Ground Truth')\n    axes[1].axis('off')\n\n    axes[2].imshow(mask_to_rgb(lc_pred, LANDCOVER_COLORS))\n    axes[2].set_title('Landcover Pred')\n    axes[2].axis('off')\n\n    mg_vis = {0: [0.8, 0.8, 0.8], 1: [0.0, 0.9, 0.4]}\n    axes[3].imshow(mask_to_rgb(mg_pred.astype(int), mg_vis))\n    axes[3].set_title('Mangrove Pred')\n    axes[3].axis('off')\n\n    axes[4].imshow(mask_to_rgb(ens_pred, ENSEMBLE_COLORS))\n    axes[4].set_title('Ensemble')\n    axes[4].axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n\nprint(\"inspect_sample() defined\")\nprint(\"Usage: inspect_sample(landcover_model, mangrove_model, dataset, idx=0)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inspect specific samples\ninspect_sample(landcover_model, mangrove_model, dataset, 0)\ninspect_sample(landcover_model, mangrove_model, dataset, 100)\ninspect_sample(landcover_model, mangrove_model, dataset, 200)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Save Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=== Saving Results ===\")\nprint()\n\nvalid_mask = targets_flat != IGNORE_INDEX\nvalid_preds = preds_flat[valid_mask]\nvalid_targets = targets_flat[valid_mask]\n\noverall_dist = {}\nfor c in range(NUM_ENSEMBLE_CLASSES):\n    overall_dist[ENSEMBLE_NAMES[c]] = float((valid_preds == c).sum() / len(valid_preds))\n\nmangrove_dist = {}\nnonmangrove_dist = {}\nfor c in range(NUM_ENSEMBLE_CLASSES):\n    m_mask = valid_targets == 1\n    nm_mask = valid_targets == 0\n    if m_mask.sum() > 0:\n        mangrove_dist[ENSEMBLE_NAMES[c]] = float((valid_preds[m_mask] == c).sum() / m_mask.sum())\n    if nm_mask.sum() > 0:\n        nonmangrove_dist[ENSEMBLE_NAMES[c]] = float((valid_preds[nm_mask] == c).sum() / nm_mask.sum())\n\nresults = {\n    'method': 'gated_ensemble',\n    'landcover_model': str(LANDCOVER_WEIGHTS),\n    'mangrove_model': str(MANGROVE_WEIGHTS),\n    'mangrove_threshold': MANGROVE_THRESHOLD,\n    'num_samples': len(dataset),\n    'ensemble_classes': ENSEMBLE_NAMES,\n    'overall_prediction_distribution': overall_dist,\n    'predictions_on_mangrove_pixels': mangrove_dist,\n    'predictions_on_non_mangrove_pixels': nonmangrove_dist,\n    'pixels_gated_to_mangrove': int(mangrove_gate.sum()),\n    'gate_percentage': float(mangrove_gate.mean() * 100),\n}\n\nresults_file = PLOTS_DIR / 'ensemble_results.json'\nwith open(results_file, 'w') as f:\n    json.dump(results, f, indent=2)\n\nprint(f\"Saved: {results_file}\")\nprint()\nprint(\"All outputs:\")\nprint(f\"  {PLOTS_DIR / 'ensemble_distribution.png'}\")\nprint(f\"  {PLOTS_DIR / 'ensemble_grid.png'}\")\nprint(f\"  {PLOTS_DIR / 'ensemble_results.json'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Legend"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(14, 3))\n\n# Ensemble legend (6 classes)\nfor i, (name, color) in enumerate(zip(ENSEMBLE_NAMES, [ENSEMBLE_COLORS[c] for c in range(NUM_ENSEMBLE_CLASSES)])):\n    axes[0].barh(i, 1, color=color, edgecolor='black')\n    axes[0].text(0.5, i, name, ha='center', va='center', fontsize=10, fontweight='bold')\naxes[0].set_title('Ensemble Output Classes', fontsize=11)\naxes[0].set_xlim(0, 1)\naxes[0].axis('off')\n\n# GT legend\nfor i, (name, color) in enumerate(zip(MANGROVE_NAMES, [MANGROVE_COLORS[c] for c in range(2)])):\n    axes[1].barh(i, 1, color=color, edgecolor='black')\n    axes[1].text(0.5, i, name, ha='center', va='center', fontsize=10, fontweight='bold')\naxes[1].barh(2, 1, color=[1, 1, 1], edgecolor='black')\naxes[1].text(0.5, 2, 'ignore (255)', ha='center', va='center', fontsize=10, fontweight='bold')\naxes[1].set_title('Ground Truth (Mangrove)', fontsize=11)\naxes[1].set_xlim(0, 1)\naxes[1].axis('off')\n\nplt.tight_layout()\nplt.savefig(PLOTS_DIR / 'ensemble_legend.png', dpi=150, bbox_inches='tight')\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mangrove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}